
@article{japkowicz_class_2002,
	title = {The class imbalance problem: {A} systematic study},
	volume = {6},
	shorttitle = {The class imbalance problem},
	url = {http://iospress.metapress.com/content/MXUG8CJKJYLNK3N0},
	abstract = {In machine learning problems, differences in prior class probabilities -- or class imbalances -- have been reported to hinder the performance of some standard classifiers, such as decision trees. This paper presents a systematic study aimed at answering three different questions. First, we attempt to understand the nature of the class imbalance problem by establishing a relationship between concept complexity, size of the training set and class imbalance level. Second, we discuss several basic re-sampling or cost-modifying methods previously proposed to deal with the class imbalance problem and compare their effectiveness. The results obtained by such methods on artificial domains are linked to results in real-world domains. Finally, we investigate the assumption that the class imbalance problem does not only affect decision tree systems but also affects other classification systems such as Neural Networks and Support Vector Machines.},
	number = {5},
	urldate = {2014-08-31},
	journal = {Intelligent Data Analysis},
	author = {Japkowicz, Nathalie and Stephen, Shaju},
	month = jan,
	year = {2002},
	pages = {429--449},
	file = {MetaPress Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/PHURN2QK/Japkowicz and Stephen - 2002 - The class imbalance problem A systematic study.pdf:application/pdf;MetaPress Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/FW8JJA67/MXUG8CJKJYLNK3N0.html:text/html}
}

@book{goetzke_are_2003,
	title = {Are {Travel} {Demand} {Forecasting} {Models} {Biased} because of {Uncorrected} {Spatial} {Autocorrelation}? {By}},
	shorttitle = {Are {Travel} {Demand} {Forecasting} {Models} {Biased} because of {Uncorrected} {Spatial} {Autocorrelation}?},
	abstract = {ABSTRACT: This paper discusses spatial autocorrelation in mode choice models, including what kind of bias it introduces and how to remedy the problem. The research shows that a spatially autocorrelated mode choice model, not uncommon because of, in terms of transit characteristics homogeneous neighborhoods, systematically overestimates transit trips from suburban transit-unfriendly areas and underestimates transit trips in the transit-friendly city center. Adding a spatial lag term into the model specification avoids the bias, however, it also changes sampling approaches, requires higher quality household forecast data and complicates forecasting},
	author = {Goetzke, Frank},
	year = {2003},
	file = {Citeseer - Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/3E2GBQBV/Goetzke - 2003 - Are Travel Demand Forecasting Models Biased becaus.pdf:application/pdf;Citeseer - Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/7QJTJPST/summary.html:text/html}
}

@article{merkle_choosing_2013,
	title = {Choosing a {Strictly} {Proper} {Scoring} {Rule}},
	volume = {10},
	issn = {1545-8490},
	url = {http://pubsonline.informs.org/doi/abs/10.1287/deca.2013.0280},
	doi = {10.1287/deca.2013.0280},
	abstract = {Strictly proper scoring rules, including the Brier score and the logarithmic score, are standard metrics by which probability forecasters are assessed and compared. Researchers often find that one's choice of strictly proper scoring rule has minimal impact on one's conclusions, but this conclusion is typically drawn from a small set of popular rules. In the context of forecasting world events, we use a recently proposed family of proper scoring rules to study the properties of a wide variety of strictly proper rules. The results indicate that conclusions vary greatly across different scoring rules, so that one's choice of scoring rule should be informed by the forecasting domain. We then describe strategies for choosing a scoring rule that meets the needs of the forecast consumer, considering three unique families of proper scoring rules.},
	number = {4},
	urldate = {2014-08-30},
	journal = {Decision Analysis},
	author = {Merkle, Edgar C. and Steyvers, Mark},
	month = dec,
	year = {2013},
	pages = {292--304},
	file = {Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/MPA93GGC/Merkle and Steyvers - 2013 - Choosing a Strictly Proper Scoring Rule.pdf:application/pdf;Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/AF4UPE2D/Merkle and Steyvers - 2013 - Choosing a Strictly Proper Scoring Rule.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/K2FH3GJ9/deca.2013.html:text/html;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/SBPA3VQN/deca.2013.html:text/html}
}

@techreport{calabrese_generalized_2011,
	type = {Working {Paper}},
	title = {Generalized {Extreme} {Value} {Regression} for {Binary} {Rare} {Events} {Data}: an {Application} to {Credit} {Defaults}},
	shorttitle = {Generalized {Extreme} {Value} {Regression} for {Binary} {Rare} {Events} {Data}},
	url = {http://econpapers.repec.org/paper/ucdwpaper/201120.htm},
	abstract = {The most used regression model with binary dependent variable is the logistic regression model. When the dependent variable represents a rare event, the logistic regression model shows relevant drawbacks. In order to overcome these drawbacks we propose the Generalized Extreme Value (GEV) regression model. In particular, in a Generalized Linear Model (GLM) with binary dependent variable we suggest the quantile function of the GEV distribution as link function, so our attention is focused on the tail of the response curve for values close to one. The estimation procedure is the maximum likelihood method. This model accommodates skewness and it presents a generalization of GLMs with log-log link function. In credit risk analysis a pivotal topic is the default probability estimation. Since defaults are rare events, we apply the GEV regression to empirical data on Italian Small and Medium Enterprises (SMEs) to model their default probabilities.},
	number = {201120},
	urldate = {2014-08-31},
	institution = {Geary Institute, University College Dublin},
	author = {Calabrese, Raffaella and Osmetti, Silvia},
	month = sep,
	year = {2011},
	file = {RePEc PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/T2BIUCKK/Calabrese and Osmetti - 2011 - Generalized Extreme Value Regression for Binary Ra.pdf:application/pdf;RePEc Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/MWU2A9F2/201120.html:text/html}
}

@inproceedings{agarwal_gev-canonical_2014,
	title = {{GEV}-{Canonical} {Regression} for {Accurate} {Binary} {Class} {Probability} {Estimation} when {One} {Class} is {Rare}},
	url = {http://jmlr.org/proceedings/papers/v32/agarwalc14.html},
	urldate = {2014-08-31},
	author = {Agarwal, Arpit and Narasimhan, Harikrishna and Kalyanakrishnan, Shivaram and Agarwal, Shivani},
	year = {2014},
	pages = {1989--1997},
	file = {Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/5C8UWF2M/Agarwal et al. - 2014 - GEV-Canonical Regression for Accurate Binary Class.pdf:application/pdf;icml14-gev-canonical.pdf:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/QHAIVT5S/icml14-gev-canonical.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/IJKW6INJ/agarwalc14.html:text/html}
}

@article{king_logistic_2001,
	title = {Logistic {Regression} in {Rare} {Events} {Data}},
	volume = {9},
	issn = {1047-1987, 1476-4989},
	url = {http://pan.oxfordjournals.org/content/9/2/137},
	abstract = {We study rare events data, binary dependent variables with dozens to thousands of times fewer ones (events, such as wars, vetoes, cases of political activism, or epidemiological infections) than zeros ({\textquotedblleft}nonevents{\textquotedblright}). In many literatures, these variables have proven difficult to explain and predict, a problem that seems to have at least two sources. First, popular statistical procedures, such as logistic regression, can sharply underestimate the probability of rare events. We recommend corrections that outperform existing methods and change the estimates of absolute and relative risks by as much as some estimated effects reported in the literature. Second, commonly used data collection strategies are grossly inefficient for rare events data. The fear of collecting data with too few events has led to data collections with huge numbers of observations but relatively few, and poorly measured, explanatory variables, such as in international conflict data with more than a quarter-million dyads, only a few of which are at war. As it turns out, more efficient sampling designs exist for making valid inferences, such as sampling all available events (e.g., wars) and a tiny fraction of nonevents (peace). This enables scholars to save as much as 99\% of their (nonfixed) data collection costs or to collect much more meaningful explanatory variables. We provide methods that link these two results, enabling both types of corrections to work simultaneously, and software that implements the methods developed.},
	language = {en},
	number = {2},
	urldate = {2014-08-31},
	journal = {Political Analysis},
	author = {King, Gary and Zeng, Langche},
	month = jan,
	year = {2001},
	pages = {137--163},
	file = {Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/QNHSPM3R/King and Zeng - 2001 - Logistic Regression in Rare Events Data.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/3EDERUZN/137.html:text/html}
}

@article{he_learning_2009,
	title = {Learning from {Imbalanced} {Data}},
	volume = {21},
	issn = {1041-4347},
	doi = {10.1109/TKDE.2008.239},
	abstract = {With the continuous expansion of data availability in many large-scale, complex, and networked systems, such as surveillance, security, Internet, and finance, it becomes critical to advance the fundamental understanding of knowledge discovery and analysis from raw data to support decision-making processes. Although existing knowledge discovery and data engineering techniques have shown great success in many real-world applications, the problem of learning from imbalanced data (the imbalanced learning problem) is a relatively new challenge that has attracted growing attention from both academia and industry. The imbalanced learning problem is concerned with the performance of learning algorithms in the presence of underrepresented data and severe class distribution skews. Due to the inherent complex characteristics of imbalanced data sets, learning from such data requires new understandings, principles, algorithms, and tools to transform vast amounts of raw data efficiently into information and knowledge representation. In this paper, we provide a comprehensive review of the development of research in learning from imbalanced data. Our focus is to provide a critical review of the nature of the problem, the state-of-the-art technologies, and the current assessment metrics used to evaluate learning performance under the imbalanced learning scenario. Furthermore, in order to stimulate future research in this field, we also highlight the major opportunities and challenges, as well as potential important research directions for learning from imbalanced data.},
	number = {9},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {He, Haibo and Garcia, E.A},
	month = sep,
	year = {2009},
	keywords = {active learning, assessment metrics., Classification, complex systems, Cost-sensitive learning, data availability, data engineering, Data mining, decision making, Imbalanced data, Imbalanced learning, kernel-based learning, knowledge discovery, Large-scale systems, learning, learning (artificial intelligence), networked systems, sampling methods},
	pages = {1263--1284},
	file = {IEEE Xplore Abstract Record:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/2B2JZXBI/abs_all.html:text/html;IEEE Xplore Abstract Record:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/IBB5FJRT/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/Q9F67VEB/He and Garcia - 2009 - Learning from Imbalanced Data.pdf:application/pdf;IEEE Xplore Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/IRJWKFZE/He and Garcia - 2009 - Learning from Imbalanced Data.pdf:application/pdf}
}

@article{vij_incorporating_2013,
	title = {Incorporating the influence of latent modal preferences on travel mode choice behavior},
	volume = {54},
	issn = {0965-8564},
	url = {http://www.sciencedirect.com/science/article/pii/S0965856413001304},
	doi = {10.1016/j.tra.2013.07.008},
	abstract = {Latent modal preferences, or modality styles, are defined as behavioral predispositions characterized by a certain travel mode or set of travel modes that an individual habitually uses. They are reflective of higher-level orientations, or lifestyles, that are hypothesized to influence all dimensions of an individual{\textquoteright}s travel and activity behavior. The objectives of this paper are to understand and quantify different modality styles, and to show how the modality styles construct can be operationalized within the context of traditional models of travel mode choice. We employ the six-week MOBIDRIVE travel diary and estimate behavioral mixture models in which the modality style provides a behavioral rationale to the way in which unobserved heterogeneity is specified in the travel model. Our analysis consists of two stages: First, we explore the presence and types of modality styles suggested by the data through the means of a descriptive analysis. Next, we develop a model that captures the influence of modality styles on two dimensions of an individual{\textquoteright}s travel behavior: travel mode choice for work tours and travel mode choice for non-work tours. The modality styles are specified as latent classes; heterogeneity across modality styles include both the modes considered (choice set) and the values of taste parameters. The modality style of an individual then influences all of his/her travel mode choice decisions for work and non-work tours. In addition, error components capture unobserved correlation across travel mode choice decisions made by the same individual. Results indicate the presence of habitual drivers who display a strong bias for using the automobile and multimodal individuals who exhibit variation in their modal preferences. Multimodal behavior is further distinguished by those who appear to be sensitive to travel times and those who appear to be insensitive. Estimation results further find that modality styles are strongly correlated with more long-term travel decisions and life-cycle characteristics.},
	urldate = {2014-09-01},
	journal = {Transportation Research Part A: Policy and Practice},
	author = {Vij, Akshay and Carrel, Andr{\'e} and Walker, Joan L.},
	month = aug,
	year = {2013},
	keywords = {Behavioral mixture model, Latent class choice model, Lifestyle, Modality styles, Travel demand modeling},
	pages = {164--178},
	file = {ScienceDirect Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/VA7B2TMX/Vij et al. - 2013 - Incorporating the influence of latent modal prefer.pdf:application/pdf;ScienceDirect Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/XBP3UQZ9/S0965856413001304.html:text/html}
}

@article{wang_generalized_2010,
	title = {Generalized {Extreme} {Value} {Regression} for {Binary} {Response} {Data}: {An} {Application} to {B}@{B} {Electronic} {Payments} {System} {Adoption}},
	volume = {4},
	copyright = {Copyright {\textcopyright} 2010 Institute of Mathematical Statistics},
	issn = {1932-6157},
	shorttitle = {{GENERALIZED} {EXTREME} {VALUE} {REGRESSION} {FOR} {BINARY} {RESPONSE} {DATA}},
	url = {http://www.jstor.org/stable/23362457},
	abstract = {In the information system research, a question of particular interest is to interpret and to predict the probability of a firm to adopt a new technology such that market promotions are targeted to only those firms that were more likely to adopt the technology. Typically, there exists significant difference between the observed number of "adopters" and "nonadopters," which is usually coded as binary response. A critical issue involved in modeling such binary response data is the appropriate choice of link functions in a regression model. In this paper we introduce a new flexible skewed link function for modeling binary response data based on the generalized extreme value (GEV) distribution. We show how the proposed GEV links provide more flexible and improved skewed link regression models than the existing skewed links, especially when dealing with imbalance between the observed number of 0's and 1's in a data. The flexibility of the proposed model is illustrated through simulated data sets and a billing data set of the electronic payments system adoption from a Fortune 100 company in 2005.},
	number = {4},
	urldate = {2014-09-21},
	journal = {The Annals of Applied Statistics},
	author = {Wang, Xia and Dey, Dipak K.},
	month = dec,
	year = {2010},
	pages = {2000--2023},
	file = {JSTOR Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/P8H43MJ5/Wang and Dey - 2010 - GENERALIZED EXTREME VALUE REGRESSION FOR BINARY RE.pdf:application/pdf}
}

@article{prato_modeling_2007,
	title = {Modeling {Route} {Choice} {Behavior}: {How} {Relevant} {Is} the {Composition} of {Choice} {Set}?},
	volume = {2003},
	shorttitle = {Modeling {Route} {Choice} {Behavior}},
	url = {http://dx.doi.org/10.3141/2003-09},
	doi = {10.3141/2003-09},
	abstract = {Most route choice models are related to revealed choice behavior and are estimated by adding alternative paths to observed routes. This paper focuses on the effects of choice set composition in route choice modeling by designing an experimental analysis of actual route choice behavior of individuals driving habitually from home to work in an urban network. The numerical analysis concentrates on a qualitative perspective, by considering path sets built with different generation techniques, and a quantitative perspective, by accounting for path sets constructed with sample size reduction from each initial choice set. Comparison of prediction accuracy across different choice sets suggests that a recently developed branch and bound algorithm generates heterogeneous routes that allow for estimating models with better prediction abilities with respect to the outcomes of the drivers' actual choices. Further, comparison of route choice models across different choice set compositions indicates that nonnested structures, such as C-logit and path size logit, yield more robust parameter estimates.},
	urldate = {2014-09-22},
	journal = {Transportation Research Record: Journal of the Transportation Research Board},
	author = {Prato, Carlo and Bekhor, Shlomo},
	month = jan,
	year = {2007},
	pages = {64--73},
	file = {Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/29C69DZE/Prato and Bekhor - 2007 - Modeling Route Choice Behavior How Relevant Is th.pdf:application/pdf;MetaPress Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/QC4TJZWW/Prato and Bekhor - 2007 - Modeling Route Choice Behavior How Relevant Is th.pdf:application/pdf;MetaPress Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/8FUVQPGI/Prato and Bekhor - 2007 - Modeling Route Choice Behavior How Relevant Is th.pdf:application/pdf;MetaPress Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/MNJRCX6P/kw77g37867x4p5v9.html:text/html;MetaPress Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/AD9RN6RF/kw77g37867x4p5v9.html:text/html;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/PVHB5E6M/2003-09.html:text/html}
}

@inproceedings{nassir_choice_2014,
	title = {A {Choice} {Set} {Generation} {Algorithm} {Suitable} for {Measuring} {Route} {Choice} {Accessibility}},
	url = {http://trid.trb.org/view/2014/C/1289516},
	urldate = {2014-09-22},
	author = {Nassir, Neema and Ziebarth, Jennifer and Sall, Elizabeth and Zorn, Lisa},
	year = {2014},
	keywords = {Accessibility, Case studies, Origin and destination, Route choice, San Francisco (California), Shortest path algorithms},
	file = {A Choice Set Generation Algorithm Sutable for Measuring Route Choice Accessibility.pdf:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/4EPQ5NI3/A Choice Set Generation Algorithm Sutable for Measuring Route Choice Accessibility.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/674QIRIS/1289516.html:text/html}
}

@article{dill_understanding_2008,
	title = {Understanding and {Measuring} {Bicycling} {Behavior}: a {Focus} on {Travel} {Time} and {Route} {Choice}},
	shorttitle = {Understanding and {Measuring} {Bicycling} {Behavior}},
	url = {http://pdxscholar.library.pdx.edu/usp_fac/28},
	journal = {Urban Studies and Planning Faculty Publications and Presentations},
	author = {Dill, Jennifer and Gliebe, John},
	month = dec,
	year = {2008},
	file = {Understanding and Measuring Bicycling Behavior_ a Focus on Travel.pdf:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/XDVMUPEB/Understanding and Measuring Bicycling Behavior_ a Focus on Travel.pdf:application/pdf;"Understanding and Measuring Bicycling Behavior\: a Focus on Travel Time" by Jennifer Dill and John Gliebe:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/XQMHHR94/28.html:text/html}
}

@inproceedings{singleton_pedestrians_2013,
	title = {Pedestrians in {Regional} {Travel} {Demand} {Forecasting} {Models}: {State} of the {Practice}},
	shorttitle = {Pedestrians in {Regional} {Travel} {Demand} {Forecasting} {Models}},
	url = {http://trid.trb.org/view.aspx?id=1242847},
	urldate = {2014-10-02},
	author = {Singleton, Patrick A. and Clifton, Kelly J.},
	year = {2013},
	keywords = {Metropolitan planning organizations, Pedestrians, Regional planning, State of the practice, Travel demand, Walking},
	file = {Pedestrians in Regional Travel Demand Forecasting Models.pdf:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/B57F5M5H/Pedestrians in Regional Travel Demand Forecasting Models.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/MEP2ZWR6/view.html:text/html}
}

@techreport{parsons_brinckerhoff_quade_&_douglas_transportation_2005,
	title = {Transportation {Models} and {Data} {Initiative}: {General} {Final} {Report}--{New} {York} {Best} {Practice} {Model}},
	shorttitle = {New {York} {Best} {Practices} {Model}},
	url = {http://www.nymtc.org/project/bpm/model/bpm_finalrpt.pdf},
	urldate = {2014-10-01},
	institution = {New York Metropolitan Transportation Council},
	author = {{Parsons Brinckerhoff Quade \& Douglas} and {PB Consult} and {AECOM Consult} and {Urbitran Associates} and {Urbanomics} and {Alex Anas \& Associates} and {NuStats International} and {George Hoyte \& Associates}},
	month = jan,
	year = {2005},
	file = {bpm_finalrpt.pdf:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/SJM2RHGX/bpm_finalrpt.pdf:application/pdf}
}

@article{swait_incorporating_1987,
	title = {Incorporating random constraints in discrete models of choice set generation},
	volume = {21},
	issn = {0191-2615},
	url = {http://www.sciencedirect.com/science/article/pii/0191261587900099},
	doi = {10.1016/0191-2615(87)90009-9},
	abstract = {This paper proposes a behavioral interpretation of the choice set generation process that is useful for structuring and specifying discrete models that incorporate this stage of choice. The key concept is the notion of random constraints, which is operationalized in the form of probabilistic choice set formation models; we thus explicitly recognize our imperfect understanding and possible lack of data about the process. Several such models are presented and discussed with respect to their behavioral plausibility and estimability. A related paper reports on the calibration of one such specification with work mode choice data from S{\~a}o Paulo, Brazil.},
	number = {2},
	urldate = {2015-01-21},
	journal = {Transportation Research Part B: Methodological},
	author = {Swait, Joffre and Ben-Akiva, Moshe},
	month = apr,
	year = {1987},
	pages = {91--102},
	file = {ScienceDirect Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/B8ITDUE2/Swait and Ben-Akiva - 1987 - Incorporating random constraints in discrete model.pdf:application/pdf;ScienceDirect Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/RZEX8CKC/0191261587900099.html:text/html}
}

@techreport{league_of_american_bicyclists_where_2014,
	title = {Where {We} {Ride}: {Analysis} of bicycling in {American} cities},
	url = {http://bikeleague.org/sites/default/files/ACS_report_2014_forweb.pdf},
	urldate = {2014-10-01},
	institution = {The League of American Bicyclists},
	author = {{League of American Bicyclists}},
	month = sep,
	year = {2014},
	file = {Where We Ride--Analysis of Bicycling in American Cities.pdf:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/MJ9DQNHZ/Where We Ride--Analysis of Bicycling in American Cities.pdf:application/pdf}
}

@techreport{cambridge_systematics_san_2002,
	title = {San {Francisco} {Travel} {Demand} {Forecasting} {Model} {Development}: {Mode} {Choice} {Models}},
	url = {http://www.sfcta.org/modeling-and-travel-forecasting},
	urldate = {2014-10-01},
	institution = {San Francisco County Transportation Authority},
	author = {{Cambridge Systematics}},
	month = oct,
	year = {2002},
	file = {Mode Choice.pdf:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/KUBSA6MC/Mode Choice.pdf:application/pdf}
}

@book{replogle_integrating_1995,
	title = {Integrating {Pedestrian} and {Bicycle} {Factors} {Into} {Regional} {Transportation} {Planning} {Models}: {Summary} of the {State}-of-the-art and {Suggested} {Steps} {Forward}},
	shorttitle = {Integrating {Pedestrian} and {Bicycle} {Factors} {Into} {Regional} {Transportation} {Planning} {Models}},
	url = {http://media.tmiponline.org/clearinghouse/udes/replogle.pdf},
	urldate = {2014-10-03},
	publisher = {Environmental Defense Fund Washington, DC},
	author = {Replogle, Michael and Fund, Environmental Defense},
	year = {1995},
	file = {[PDF] from tmiponline.org:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/5RIHVM9A/Replogle and Fund - 1995 - Integrating Pedestrian and Bicyle Factors Into Reg.pdf:application/pdf}
}

@article{steinberg_hybrid_1998,
	title = {The hybrid {CART}-{Logit} model in classification and data mining},
	url = {http://media.salford-systems.com/pdf/the-hybrid-cart-logit-model-in-classification-and-data%20mining-1998.pdf},
	urldate = {2014-11-20},
	journal = {Salford Systems White Paper},
	author = {Steinberg, Dan and Cardell, N. Scott},
	year = {1998},
	file = {[PDF] from salford-systems.com:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/X9F5C3TW/Steinberg and Cardell - 1998 - The hybrid CART-Logit model in classification and .pdf:application/pdf}
}

@inproceedings{wallace_class_2011,
	title = {Class imbalance, redux},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6137280},
	urldate = {2015-01-18},
	booktitle = {Data {Mining} ({ICDM}), 2011 {IEEE} 11th {International} {Conference} on},
	publisher = {IEEE},
	author = {Wallace, Byron C. and Small, Kevin and Brodley, Carla E. and Trikalinos, Thomas A.},
	year = {2011},
	pages = {754--763},
	file = {[PDF] from ust.hk:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/Z9BAP36E/Wallace et al. - 2011 - Class imbalance, redux.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/5KXANSVF/abs_all.html:text/html}
}

@article{czado_effect_1992,
	title = {The effect of link misspecification on binary regression inference},
	volume = {33},
	issn = {0378-3758},
	url = {http://www.sciencedirect.com/science/article/pii/0378375892900695},
	doi = {10.1016/0378-3758(92)90069-5},
	abstract = {This paper quantifies the large and small-sample effects of link misspecification on binary regression analysis. The large-sample effects are determined by deriving the asymptotic properties of the maximum likelihood estimators (MLEs) of the regression coefficients and event probabilities assuming an incorrect link is used. The MLEs are asymptotically normal under regularity conditions but have asymptotic bias and are inefficient. For the important case of a fitted logistic link, detailed assessment is made of the asymptotic mean and variance of the MLE of the regression coefficients and the predicted probability at a given covariate for several non-logistic true link functions. The finite sample effects are investigated in a simulation study for sample sizes 20, 50, 100, and 200. The bias and mean squared errors of the logistic link MLE of the regression coefficients and predicted probability (at a given covariate) are determined for the same set of true links included in the asymptotic study. The results show that skewness has a greater effect on the bias and mean squared error of logistic MLEs than tail weight. Assessment is made of the sample sizes for which the asymptotic results apply.},
	number = {2},
	urldate = {2015-01-18},
	journal = {Journal of Statistical Planning and Inference},
	author = {Czado, Claudia and Santner, Thomas J.},
	month = nov,
	year = {1992},
	keywords = {bias, Binary regression data, cohort sampling, link misspecification, Maximum likelihood estimation, mean squared error, parametric link families, robustness},
	pages = {213--231},
	file = {ScienceDirect Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/9WR6M565/Czado and Santner - 1992 - The effect of link misspecification on binary regr.pdf:application/pdf;ScienceDirect Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/5RKPFU3N/0378375892900695.html:text/html}
}

@techreport{california_department_of_transportation_2010-2012_2013,
	title = {2010-2012 {California} {Household} {Travel} {Survey} {Final} {Report}},
	url = {http://www.dot.ca.gov/hq/tsip/FinalReport.pdf},
	urldate = {2014-08-01},
	author = {{California Department of Transportation}},
	month = jun,
	year = {2013}
}

@article{reid_convexity_2012,
	title = {The {Convexity} and {Design} of {Composite} {Multiclass} {Losses}},
	url = {http://arxiv.org/abs/1206.4663},
	abstract = {We consider composite loss functions for multiclass prediction comprising a proper (i.e., Fisher-consistent) loss over probability distributions and an inverse link function. We establish conditions for their (strong) convexity and explore the implications. We also show how the separation of concerns afforded by using this composite representation allows for the design of families of losses with the same Bayes risk.},
	urldate = {2014-12-18},
	journal = {arXiv:1206.4663 [cs, stat]},
	author = {Reid, Mark and Williamson, Robert and Sun, Peng},
	month = jun,
	year = {2012},
	note = {arXiv: 1206.4663},
	keywords = {Computer Science - Learning, Statistics - Machine Learning},
	file = {arXiv\:1206.4663 PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/IF4658X7/Reid et al. - 2012 - The Convexity and Design of Composite Multiclass L.pdf:application/pdf;arXiv\:1206.4663 PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/KW28BHDC/Reid et al. - 2012 - The Convexity and Design of Composite Multiclass L.pdf:application/pdf;arXiv.org Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/B7W5N7A3/1206.html:text/html;arXiv.org Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/34AZHXZT/1206.html:text/html}
}

@article{reid_composite_2010,
	title = {Composite binary losses},
	volume = {11},
	url = {http://dl.acm.org/citation.cfm?id=1953012},
	urldate = {2014-12-19},
	journal = {The Journal of Machine Learning Research},
	author = {Reid, Mark D. and Williamson, Robert C.},
	year = {2010},
	pages = {2387--2422},
	file = {[PDF] from arxiv.org:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/JVAXHDI4/Reid and Williamson - 2010 - Composite binary losses.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/UKG5AEH7/citation.html:text/html}
}

@article{scott_calibrated_2012,
	title = {Calibrated asymmetric surrogate losses},
	volume = {6},
	issn = {1935-7524},
	url = {http://projecteuclid.org/euclid.ejs/1337951630},
	doi = {10.1214/12-EJS699},
	abstract = {Surrogate losses underlie numerous state-of-the-art binary classification algorithms, such as support vector machines and boosting. The impact of a surrogate loss on the statistical performance of an algorithm is well-understood in symmetric classification settings, where the misclassification costs are equal and the loss is a margin loss. In particular, classification-calibrated losses are known to imply desirable properties such as consistency. While numerous efforts have been made to extend surrogate loss-based algorithms to asymmetric settings, to deal with unequal misclassification costs or training data imbalance, considerably less attention has been paid to whether the modified loss is still calibrated in some sense. This article extends the theory of classification-calibrated losses to asymmetric problems. As in the symmetric case, it is shown that calibrated asymmetric surrogate losses give rise to excess risk bounds, which control the expected misclassification cost in terms of the excess surrogate risk. This theory is illustrated on the class of uneven margin losses, and the uneven hinge, squared error, exponential, and sigmoid losses are treated in detail.},
	language = {EN},
	urldate = {2014-12-23},
	journal = {Electronic Journal of Statistics},
	author = {Scott, Clayton},
	year = {2012},
	mrnumber = {MR2988435},
	zmnumber = {06166984},
	keywords = {classification calibrated, cost-sensitive classification, excess risk bound, Imbalanced data, Surrogate loss, uneven margin},
	pages = {958--992},
	file = {Calibrated Asymmetric Surrogate Losses.pdf:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/JZ4SKIZS/Calibrated Asymmetric Surrogate Losses.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/6MJXA4DK/1337951630.html:text/html}
}

@book{buja_loss_2005,
	title = {Loss {Functions} for {Binary} {Class} {Probability} {Estimation} and {Classification}: {Structure} and {Applications},{\textquotedblright} manuscript, available at www-stat.wharton.upenn.edu/ buja},
	shorttitle = {Loss {Functions} for {Binary} {Class} {Probability} {Estimation} and {Classification}},
	abstract = {What are the natural loss functions or fitting criteria for binary class probability estimation? This question has a simple answer: so-called {\textquotedblleft}proper scoring rules{\textquotedblright}, that is, functions that score probability estimates in view of data in a Fisher-consistent manner. Proper scoring rules comprise most loss functions currently in use: log-loss, squared error loss, boosting loss, and as limiting cases cost-weighted misclassification losses. Proper scoring rules have a rich structure: {\textbullet} Every proper scoring rules is a mixture (limit of sums) of cost-weighted misclassification losses. The mixture is specified by a weight function (or measure) that describes which misclassification cost weights are most emphasized by the proper scoring rule. {\textbullet} Proper scoring rules permit Fisher scoring and Iteratively Reweighted LS algorithms for model fitting. The weights are derived from a link function and the above weight function. {\textbullet} Proper scoring rules are in a 1-1 correspondence with information measures for tree-based classification.},
	author = {Buja, Andreas and Stuetzle, Werner and Shen, Yi},
	year = {2005},
	file = {Citeseer - Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/SMKXWS4U/summary.html:text/html;paper-proper-scoring.pdf:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/KJ2V6ADM/paper-proper-scoring.pdf:application/pdf}
}

@article{perez-sanchez_bayesian_2014,
	title = {{BAYESIAN} {ASYMMETRIC} {LOGIT} {MODEL} {FOR} {DETECTING} {RISK} {FACTORS} {IN} {MOTOR} {RATEMAKING}},
	volume = {44},
	issn = {1783-1350},
	url = {http://journals.cambridge.org/article_S0515036113000329},
	doi = {10.1017/asb.2013.32},
	abstract = {Modelling automobile insurance claims is a crucial component in the ratemaking procedure. This paper focuses on the probability that a policyholder reports a claim, where the classical logit link does not provide a right model. This is so because databases related with automobile claims are often unbalanced, containing more non-claims than the presence of claims. In this work an asymmetric logit model, which takes into account the large number of non-claims in the portfolio, is considered. Both, logit and asymmetric logit models from a Bayesian point of view, are used to a sample that was collected from a major automobile insurance company in Spain in 2009, resulting in a dataset of 2,000 passenger vehicle. We establish the validity of the asymmetric model in front of the conventional logit link. The use of a garage, the age of the vehicle and the duration of the client's relation with the company are all shown to be significant explanatory variables by the logit model. The asymmetric model includes, in addition, the length of time the policyholder has held a driving licence and the type of use made of the vehicle. The asymmetric model provides a better fit to the data examined.},
	number = {02},
	urldate = {2014-12-25},
	journal = {ASTIN Bulletin},
	author = {P{\'e}rez-S{\'a}nchez, J.m. and Negr{\'i}n-Hern{\'a}ndez, M.a. and Garc{\'i}a-Garc{\'i}a, C. and G{\'o}mez-D{\'e}niz, E.},
	month = may,
	year = {2014},
	pages = {445--457},
	file = {Cambridge Journals Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/9746BS4H/displayAbstract.html:text/html;Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/8CB77J4Q/P{\'e}rez-S{\'a}nchez et al. - 2014 - BAYESIAN ASYMMETRIC LOGIT MODEL FOR DETECTING RISK.pdf:application/pdf}
}

@article{stukel_generalized_1988,
	title = {Generalized {Logistic} {Models}},
	volume = {83},
	issn = {0162-1459},
	url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1988.10478613},
	doi = {10.1080/01621459.1988.10478613},
	abstract = {A class of models indexed by two shape parameters is introduced, both to extend the scope of the standard logistic model to asymmetric probability curves and improve the fit in the noncentral probability regions. One-parameter subclasses can be used to examine symmetric or asymmetric deviations from the logistic model. The delta algorithm is adapted to obtain maximum likelihood estimates of the parameters. A review is made of other proposed generalizations. The standard linear logistic model is widely used for modeling the dependence of binary data on explanatory variables. Its success is due to its broad applicability, simplicity of form, and ease of interpretation. This model works well for many common applications; however, it assumes that the expected probability curve $\mu$($\eta$) is skew-symmetric about $\mu$ = {\textonehalf} and that the shape of $\mu$($\eta$) is the cumulative distribution function of the logistic distribution. Symmetric data with a shallower or steeper slope of ascent may not be fitted well by this model, nor is there any provision for treating the two tails of the estimated curve $\mu$($\eta$) asymmetrically or fitting different distributions for $\mu$($\eta$). This article introduces a class of models, indexed by one or two shape parameters, that encompasses a wider range of situations than the standard logistic model (although the standard model is included). The shape parameters have been specifically designed to modify the behavior of the curve in the extreme-probability regions where problems of lack of fit may occur, while allowing for asymmetric treatment of the two tails. Members of this family approximate the Gaussian, Laplace, and extreme minimum and maximum distributions up to the first four moments. The model can be collapsed to several simpler one-parameter symmetric and asymmetric formulations.},
	number = {402},
	urldate = {2014-12-25},
	journal = {Journal of the American Statistical Association},
	author = {Stukel, Th{\'e}r{\`e}se A.},
	month = jun,
	year = {1988},
	pages = {426--431},
	file = {Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/UVM38GBC/Stukel - 1988 - Generalized Logistic Models.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/T87PXQER/01621459.1988.html:text/html}
}

@article{chen_new_1999,
	title = {A {New} {Skewed} {Link} {Model} for {Dichotomous} {Quantal} {Response} {Data}},
	volume = {94},
	copyright = {Copyright {\textcopyright} 1999 American Statistical Association},
	issn = {0162-1459},
	url = {http://www.jstor.org/stable/2669933},
	doi = {10.2307/2669933},
	abstract = {The logit, probit, and student t-links are widely used in modeling dichotomous quantal response data. Most of the commonly used link functions are symmetric, except the complementary log-link. However, in some applications the overall fit can be significantly improved by the use of an asymmetric link. In this article we propose a new skewed link model for analyzing binary response data with covariates. Introducing a skewed distribution for the underlying latent variable, we develop a class of asymmetric link models for binary response data. Using a Bayesian approach, we first characterize the propriety of the posterior distributions using standard improper priors. We further propose informative priors using historical data from a similar previous study. We examine the proposed method through a large-scale simulation study and use data from a prostate cancer study to demonstrate the use of historical data in Bayesian model fitting and comparison of skewed link models.},
	number = {448},
	urldate = {2014-12-25},
	journal = {Journal of the American Statistical Association},
	author = {Chen, Ming-Hui and Dey, Dipak K. and Shao, Qi-Man},
	month = dec,
	year = {1999},
	pages = {1172--1186},
	file = {JSTOR Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/AZAHEU9F/Chen et al. - 1999 - A New Skewed Link Model for Dichotomous Quantal Re.pdf:application/pdf}
}

@article{bermudez_bayesian_2008,
	title = {A {Bayesian} dichotomous model with asymmetric link for fraud in insurance},
	volume = {42},
	issn = {0167-6687},
	url = {http://www.sciencedirect.com/science/article/pii/S0167668707000947},
	doi = {10.1016/j.insmatheco.2007.08.002},
	abstract = {Standard binary models have been developed to describe the behavior of consumers when they are faced with two choices. The classical logit model presents the feature of the symmetric link function. However, symmetric links do not provide good fits for data where one response is much more frequent than the other (as it happens in the insurance fraud context). In this paper, we use an asymmetric or skewed logit link, proposed by Chen et~al. [Chen, M., Dey, D., Shao, Q., 1999. A new skewed link model for dichotomous quantal response data. J. Amer. Statist. Assoc. 94 (448), 1172{\textendash}1186], to fit a fraud database from the Spanish insurance market. Bayesian analysis of this model is developed by using data augmentation and Gibbs sampling. The results show that the use of an asymmetric link notably improves the percentage of cases that are correctly classified after the model estimation.},
	number = {2},
	urldate = {2014-12-25},
	journal = {Insurance: Mathematics and Economics},
	author = {Berm{\'u}dez, Ll. and P{\'e}rez, J. M. and Ayuso, M. and G{\'o}mez, E. and V{\'a}zquez, F. J.},
	month = apr,
	year = {2008},
	keywords = {Automobile insurance, Bayesian statistics, Fraud, Gibbs sampling, IB40, IM20, Logit model},
	pages = {779--786},
	file = {ScienceDirect Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/3FDEZPE8/Berm{\'u}dez et al. - 2008 - A Bayesian dichotomous model with asymmetric link .pdf:application/pdf;ScienceDirect Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/R5TSDSFV/S0167668707000947.html:text/html}
}

@article{saez-castillo_bayesian_2010,
	title = {Bayesian {Analysis} of {Nosocomial} {Infection} {Risk} and {Length} of {Stay} in a {Department} of {General} and {Digestive} {Surgery}},
	volume = {13},
	copyright = {{\textcopyright} 2009, International Society for Pharmacoeconomics and Outcomes Research (ISPOR)},
	issn = {1524-4733},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1524-4733.2009.00680.x/abstract},
	doi = {10.1111/j.1524-4733.2009.00680.x},
	abstract = {Objective:  Nosocomial infection is one of the main causes of morbidity and mortality in patients admitted to hospital. One aim of this study is to determine its intrinsic and extrinsic risk factors. Nosocomial infection also increases the duration of hospital stay. We quantify, in relative terms, the increased duration of the hospital stay when a patient has the infection. Methods:  We propose the use of logistic regression models with an asymmetric link to estimate the probability of a patient suffering a nosocomial infection. We use Poisson-Gamma regression models as a multivariate technique to detect the factors that really influence the average hospital stay of infected and noninfected patients. For both models, frequentist and Bayesian estimations were carried out and compared. Results:  The models are applied to data from 1039 patients operated on in a Spanish hospital. Length of stay, the existance of a preoperative stay and obesity were found the main risk factors for a nosomial infection. The existence of a nosocomial infection multiplies the length of stay in the hospital by a factor of 2.87. Conclusion:  The results show that the asymmetric logit improves the predictive capacity of conventional logistic regressions},
	language = {en},
	number = {4},
	urldate = {2014-12-25},
	journal = {Value in Health},
	author = {S{\'a}ez-Castillo, Antonio Jos{\'e} and Olmo-Jim{\'e}nez, Mar{\'i}a Jos{\'e} and P{\'e}rez S{\'a}nchez, Jos{\'e} Mar{\'i}a and Negr{\'i}n Hern{\'a}ndez, Miguel {\'A}ngel and Arcos-Navarro, {\'A}ngel and D{\'i}az-Oller, Juan},
	year = {2010},
	keywords = {asymmetric logit, Bayesian analysis, length of stay in hospital, Logistic regression, nosocomial infection risk, Poisson-Gamma model},
	pages = {431--439},
	file = {Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/3JIPDG2Q/S{\'a}ez-Castillo et al. - 2010 - Bayesian Analysis of Nosocomial Infection Risk and.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/WIZQZDFP/full.html:text/html}
}

@article{jiang_new_2013,
	title = {A new class of flexible link functions with application to species co-occurrence in cape floristic region},
	volume = {7},
	issn = {1932-6157},
	url = {http://arxiv.org/abs/1401.1915},
	doi = {10.1214/13-AOAS663},
	abstract = {Understanding the mechanisms that allow biological species to co-occur is of great interest to ecologists. Here we investigate the factors that influence co-occurrence of members of the genus Protea in the Cape Floristic Region of southwestern Africa, a global hot spot of biodiversity. Due to the binomial nature of our response, a critical issue is to choose appropriate link functions for the regression model. In this paper we propose a new family of flexible link functions for modeling binomial response data. By introducing a power parameter into the cumulative distribution function (c.d.f.) corresponding to a symmetric link function and its mirror reflection, greater flexibility in skewness can be achieved in both positive and negative directions. Through simulated data sets and analysis of the Protea co-occurrence data, we show that the proposed link function is quite flexible and performs better against link misspecification than standard link functions.},
	number = {4},
	urldate = {2014-12-25},
	journal = {The Annals of Applied Statistics},
	author = {Jiang, Xun and Dey, Dipak K. and Prunier, Rachel and Wilson, Adam M. and Holsinger, Kent E.},
	month = dec,
	year = {2013},
	note = {arXiv: 1401.1915},
	keywords = {Statistics - Applications},
	pages = {2180--2204},
	file = {arXiv\:1401.1915 PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/45EI7DMW/Jiang et al. - 2013 - A new class of flexible link functions with applic.pdf:application/pdf;arXiv.org Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/CICX766T/1401.html:text/html}
}

@book{train_discrete_2009,
	address = {New York, NY, USA},
	edition = {2},
	title = {Discrete {Choice} {Methods} {With} {Simulation}},
	isbn = {978-0-521-76655-5},
	shorttitle = {Discrete {Choice} {Methods} {With} {Simulation}},
	abstract = {This book describes the new generation of discrete choice methods, focusing on the many advances that are made possible by simulation. Researchers use these statistical methods to examine
the choices that  consumers, households, firms, and other agents
make. Each of the major models is covered: logit, generalized
extreme value (including nested and cross-nested logits), probit, and mixed logit, plus a variety of specifications that build on these basics. Simulation-assisted estimation procedures are investigated and compared, including maximum simulated likelihood, method of simulated moments, and method of simulated scores. Procedures for drawing from densities are described, including variance reduction techniques such as antithetics and Halton draws. Recent advances in Bayesian procedures are explored, including the use of the Metropolis{\textendash}Hastings algorithm and its variant Gibbs sampling. This second edition adds
chapters on endogeneity and expectation-maximization algorithms. No other book incorporates all these topics, which have
arisen in the past 25 years. The procedures are applicable in many fields, including energy, transportation, environmental
studies, health, labor, and marketing.},
	publisher = {Cambridge University Press},
	author = {Train, Kenneth},
	year = {2009},
	file = {Discrete Choice Methods with Simulation by Kenneth E Train.pdf:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/NK2MMKX7/Discrete Choice Methods with Simulation by Kenneth E Train.pdf:application/pdf}
}

@article{das_generalized_2014,
	title = {On generalized multinomial models and joint percentile estimation},
	volume = {145},
	issn = {0378-3758},
	url = {http://www.sciencedirect.com/science/article/pii/S0378375813002103},
	doi = {10.1016/j.jspi.2013.08.015},
	abstract = {This article proposes a family of link functions for the multinomial response model. The link family includes the multicategorical logistic link as one of its members. Conditions for the local orthogonality of the link and the regression parameters are given. It is shown that local orthogonality of the parameters in a neighbourhood makes the link family location and scale invariant. Confidence regions for jointly estimating the percentiles based on the parametric family of link functions are also determined. A numerical example based on a combination drug study is used to illustrate the proposed parametric link family and the confidence regions for joint percentile estimation.},
	urldate = {2015-03-28},
	journal = {Journal of Statistical Planning and Inference},
	author = {Das, I. and Mukhopadhyay, S.},
	month = feb,
	year = {2014},
	keywords = {Confidence regions, Multicategorical logistic link, Parameter orthogonality, Standardization},
	pages = {190--203},
	file = {ScienceDirect Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/VPJTU28W/Das and Mukhopadhyay - 2014 - On generalized multinomial models and joint percen.pdf:application/pdf;ScienceDirect Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/GGXHZPWC/S0378375813002103.html:text/html}
}

@article{vij_preference_2014,
	title = {Preference endogeneity in discrete choice models},
	volume = {64},
	issn = {0191-2615},
	url = {http://www.sciencedirect.com/science/article/pii/S0191261514000344},
	doi = {10.1016/j.trb.2014.02.008},
	abstract = {Existing models of disaggregate decision-making assume that preferences, as indicated by taste parameters and choice sets, are characteristics of the decision-maker that are exogenous to the choice situation and stable over time. Though the assumption has allowed travel demand analysts to use these models to forecast changes in observable behavior in response to changes in the decision-making environment, the assumption has overlooked the influence of these changes on the preferences underlying observable behavior. As a consequence, the use of these models has been limited to forecasting horizons over which preferences can reasonably be assumed to be stable. We build on Latent Class Choice Models (LCCMs) to allow for preference endogeneity. Conventional LCCMs formulate class membership as some function of the decision-maker{\textquoteright}s characteristics, but they ignore the impact of alternative attributes, which usually enter the class-specific choice models, on class membership. In this paper we introduce LCCMs with feedback from the class-specific choice models to the class membership model through the construct of consumer surplus. Class membership is hypothesized to be a function not only of the characteristics of the decision-maker but also of the consumer surplus offered by each class, which in turn is a function of alternative attributes, taste parameters and choice sets. The framework is applied to a case study on travel mode choice behavior. A comparison between LCCMs with feedback and traditional models that do not allow for preference endogeneity finds that the former performs better in terms of fit and offers greater behavioral insights, and that the latter can lead to biased forecasts.},
	urldate = {2015-01-06},
	journal = {Transportation Research Part B: Methodological},
	author = {Vij, Akshay and Walker, Joan L.},
	month = jun,
	year = {2014},
	keywords = {Discrete choice, Latent class choice models, Preference endogeneity, Travel behavior},
	pages = {90--105},
	file = {ScienceDirect Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/KCMNEBRV/Vij and Walker - 2014 - Preference endogeneity in discrete choice models.pdf:application/pdf;ScienceDirect Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/AV8SHB9J/Vij and Walker - 2014 - Preference endogeneity in discrete choice models.pdf:application/pdf;ScienceDirect Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/BNZZVAZS/S0191261514000344.html:text/html;ScienceDirect Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/PZIB8DRI/S0191261514000344.html:text/html}
}

@incollection{masnadi-shirazi_design_2009,
	title = {On the {Design} of {Loss} {Functions} for {Classification}: theory, robustness to outliers, and {SavageBoost}},
	shorttitle = {On the {Design} of {Loss} {Functions} for {Classification}},
	url = {http://papers.nips.cc/paper/3591-on-the-design-of-loss-functions-for-classification-theory-robustness-to-outliers-and-savageboost.pdf},
	urldate = {2015-01-19},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 21},
	publisher = {Curran Associates, Inc.},
	author = {Masnadi-shirazi, Hamed and Vasconcelos, Nuno},
	editor = {Koller, D. and Schuurmans, D. and Bengio, Y. and Bottou, L.},
	year = {2009},
	pages = {1049--1056},
	file = {NIPS Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/KGGAPPXM/Masnadi-shirazi and Vasconcelos - 2009 - On the Design of Loss Functions for Classification.pdf:application/pdf;NIPS Snapshort:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/AZAT73CD/3591-on-the-design-of-loss-functions-for-classification-theory-robustness-to-outliers-and-savag.html:text/html}
}

@book{mccullagh_generalized_1989,
	address = {Boca Raton},
	edition = {2 edition},
	title = {Generalized {Linear} {Models}, {Second} {Edition}},
	isbn = {978-0-412-31760-6},
	abstract = {The success of the first edition of Generalized Linear Models led to the updated Second Edition, which continues to provide a definitive unified, treatment of methods for the analysis of diverse types of data. Today, it remains popular for its clarity, richness of content and direct relevance to agricultural, biological, health, engineering, and other applications.The authors focus on examining the way a response variable depends on a combination of explanatory variables, treatment, and classification variables. They give particular emphasis to the important case where the dependence occurs through some unknown, linear combination of the explanatory variables.The Second Edition includes topics added to the core of the first edition, including conditional and marginal likelihood methods, estimating equations, and models for dispersion effects and components of dispersion. The discussion of other topics-log-linear and related models, log odds-ratio regression models, multinomial response models, inverse linear and related models, quasi-likelihood functions, and model checking-was expanded and incorporates significant revisions.Comprehension of the material requires simply a knowledge of matrix theory and the basic ideas of probability theory, but for the most part, the book is self-contained. Therefore, with its worked examples, plentiful exercises, and topics of direct use to researchers in many disciplines, Generalized Linear Models serves as ideal text, self-study guide, and reference.},
	language = {English},
	publisher = {Chapman and Hall/CRC},
	author = {McCullagh, P. and Nelder, John A.},
	month = aug,
	year = {1989}
}

@article{swait_choice_2001,
	title = {Choice set generation within the generalized extreme value family of discrete choice models},
	volume = {35},
	url = {http://www.sciencedirect.com/science/article/pii/S0191261500000291},
	number = {7},
	urldate = {2015-01-21},
	journal = {Transportation Research Part B: Methodological},
	author = {Swait, Joffre},
	year = {2001},
	keywords = {Choice set generation, Discrete choice models, GEV models},
	pages = {643--666},
	file = {ScienceDirect Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/GX88CVG2/Swait - 2001 - Choice set generation within the generalized extre.pdf:application/pdf;ScienceDirect Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/PJS9F9AJ/S0191261500000291.html:text/html;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/DWKWVB9C/S0191261500000291.html:text/html}
}

@techreport{vijverberg_betit:_2000,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Betit: {A} {Family} {That} {Nests} {Probit} and {Logit}},
	shorttitle = {Betit},
	url = {http://papers.ssrn.com/abstract=264789},
	abstract = {This paper proposes a dichotomous choice model that is based on a transformed beta (or "z") distribution. This model, called betit, nests both logit and probit and allows for various skewed and peaked disturbance densities. Because the shape of this density affects the estimated relation between the dichotomous choice variable and its determinants, the greater flexibility of the transformed beta distribution is useful in generating more accurate representations of this relationship. The paper considers asymptotic biases of the logit and probit models under conditions where betit should have been used. It also investigates small sample power and provides two examples of applications that illustrative of the capability of the betit model.},
	number = {ID 264789},
	urldate = {2015-02-17},
	institution = {Social Science Research Network},
	author = {Vijverberg, Wim P. M.},
	month = dec,
	year = {2000},
	keywords = {Beta distribution, Dichotomous choice model, Logit, probit},
	file = {betit_a_family_that_nests_probit_and_logit.pdf:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/D3IUCIR7/betit_a_family_that_nests_probit_and_logit.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/U3MQ5F3R/papers.html:text/html}
}

@techreport{vijverberg_pregibit:_2012,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Pregibit: {A} {Family} of {Discrete} {Choice} {Models}},
	shorttitle = {Pregibit},
	url = {http://papers.ssrn.com/abstract=2010974},
	abstract = {The pregibit discrete choice model is built on a distribution that allows symmetry or asymmetry and thick tails, thin tails or no tails. Thus the model is much richer than the traditional models that are typically used to study behavior that generates discrete choice outcomes. Pregibit nests logit, approximately nests probit, loglog, cloglog and gosset models, and yields a linear probability model that is solidly founded on the discrete choice framework that underlies logit and probit.},
	number = {ID 2010974},
	urldate = {2015-02-17},
	institution = {Social Science Research Network},
	author = {Vijverberg, Chu-Ping C. and Vijverberg, Wim P. M.},
	month = feb,
	year = {2012},
	keywords = {asymmetry, Discrete choice, Logit, mortgage application, post-secondary education, probit},
	file = {pregibit_a_family_of_discrete_choice_models.pdf:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/UMK4ZZQ2/pregibit_a_family_of_discrete_choice_models.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/I6274EVT/papers.html:text/html}
}

@article{prentice_generalization_1976,
	title = {A {Generalization} of the {Probit} and {Logit} {Methods} for {Dose} {Response} {Curves}},
	volume = {32},
	copyright = {Copyright {\textcopyright} 1976 International Biometric Society},
	issn = {0006-341X},
	url = {http://www.jstor.org/stable/2529262},
	doi = {10.2307/2529262},
	abstract = {The relationship between response probability and dosage in quantal response bioassay is modelled using a four parameter class. In addition to location and scale quantities the model includes two shape parameters that essentially index skewness and heaviness of tails of the dose-response curve. The class of models includes such special cases as the logistic, normal, extreme minimum value, extreme maximum value, double exponential, exponential and reflected exponential distribution functions. Score tests are derived for logistic and normal hypotheses and certain submodels are discussed for which the model fitting is computationally convenient. The data of Bliss [1935] illustrates the potential improvement over usual methods in the estimation of critical dose levels.},
	number = {4},
	urldate = {2015-02-22},
	journal = {Biometrics},
	author = {Prentice, Ross L.},
	month = dec,
	year = {1976},
	pages = {761--768},
	file = {JSTOR Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/9J6W6RPB/Prentice - 1976 - A Generalization of the Probit and Logit Methods f.pdf:application/pdf}
}

@article{nagler_scobit:_1994,
	title = {Scobit: {An} {Alternative} {Estimator} to {Logit} and {Probit}},
	volume = {38},
	copyright = {Copyright {\textcopyright} 1994 Midwest Political Science Association},
	issn = {0092-5853},
	shorttitle = {Scobit},
	url = {http://www.jstor.org/stable/2111343},
	doi = {10.2307/2111343},
	abstract = {Logit and probit, the two most common techniques for estimation of models with a dichotomous dependent variable, impose the assumption that individuals with a probability of .5 of choosing either of two alternatives are most sensitive to changes in independent variables. This assumption is imposed by the estimation technique because both the logistic and normal density functions are symmetric about zero. Rather than let methodology dictate substantive assumptions, I propose an alternative distribution for the disturbances to the normal or logistic distribution. The resulting estimator developed here, scobit (or skewed-logit), is shown to be appropriate where individuals with any initial probability of choosing either of two alternatives are most sensitive to changes in independent variables. I then demonstrate that voters with initial probability of voting of less than .5 are most sensitive to changes in independent variables. And I examine whether individuals with low levels of education or high levels of education are most sensitive to changes in voting laws with respect to their probability of voting.},
	number = {1},
	urldate = {2015-02-22},
	journal = {American Journal of Political Science},
	author = {Nagler, Jonathan},
	month = feb,
	year = {1994},
	pages = {230--255},
	file = {JSTOR Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/9I64HNW4/Nagler - 1994 - Scobit An Alternative Estimator to Logit and Prob.pdf:application/pdf}
}

@article{koenker_parametric_2009,
	series = {Nonparametric and {Robust} {Methods} in {Econometrics}},
	title = {Parametric links for binary choice models: {A} {Fisherian}{\textendash}{Bayesian} colloquy},
	volume = {152},
	issn = {0304-4076},
	shorttitle = {Parametric links for binary choice models},
	url = {http://www.sciencedirect.com/science/article/pii/S0304407609000207},
	doi = {10.1016/j.jeconom.2009.01.009},
	abstract = {The familiar logit and probit models provide convenient settings for many binary response applications, but a larger class of link functions may be occasionally desirable. Two parametric families of link functions are investigated: the Gosset link based on the Student t latent variable model with the degrees of freedom parameter controlling the tail behavior, and the Pregibon link based on the (generalized) Tukey $\lambda$ family, with two shape parameters controlling skewness and tail behavior. Both Bayesian and maximum likelihood methods for estimation and inference are explored, compared and contrasted. In applications, like the propensity score matching problem discussed below, where it is critical to have accurate estimates of the conditional probabilities, we find that misspecification of the link function can create serious bias. Bayesian point estimation via MCMC performs quite competitively with MLE methods; however nominal coverage of Bayes credible regions is somewhat more problematic.},
	number = {2},
	urldate = {2015-02-22},
	journal = {Journal of Econometrics},
	author = {Koenker, Roger and Yoon, Jungmo},
	month = oct,
	year = {2009},
	keywords = {Binary response model, Cauchit, Link function, Markov chain Monte-Carlo},
	pages = {120--130},
	file = {ScienceDirect Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/5HWNRW5T/Koenker and Yoon - 2009 - Parametric links for binary choice models A Fishe.pdf:application/pdf;ScienceDirect Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/K2G3JGKD/Koenker and Yoon - 2009 - Parametric links for binary choice models A Fishe.pdf:application/pdf;ScienceDirect Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/JPF2UINK/S0304407609000207.html:text/html;ScienceDirect Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/2PB9ZEDK/S0304407609000207.html:text/html}
}

@article{pregibon_goodness_1980,
	title = {Goodness of {Link} {Tests} for {Generalized} {Linear} {Models}},
	volume = {29},
	copyright = {Copyright {\textcopyright} 1980 Royal Statistical Society},
	issn = {0035-9254},
	url = {http://www.jstor.org/stable/2346405},
	doi = {10.2307/2346405},
	abstract = {Data analytic procedures are proposed to examine the adequacy of the hypothesized link used in fitting a generalized linear model. Through model expansion and linearization, tests and estimation techniques are provided. These procedures, along with the release of GLIM3, enable the user to examine routinely and objectively the fit of an hypothesized model. Examples are presented to illustrate the testing and fitting procedure.},
	number = {1},
	urldate = {2015-02-22},
	journal = {Journal of the Royal Statistical Society. Series C (Applied Statistics)},
	author = {Pregibon, Daryl},
	month = jan,
	year = {1980},
	pages = {15--14},
	file = {JSTOR Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/U7H2CGCX/Pregibon - 1980 - Goodness of Link Tests for Generalized Linear Mode.pdf:application/pdf}
}

@article{liu_robit_2004,
	title = {Robit regression: a simple robust alternative to logistic and probit regression},
	shorttitle = {Robit regression},
	url = {http://www.stat.purdue.edu/~chuanhai/teaching/Stat598A/robit.pdf},
	urldate = {2015-02-22},
	journal = {Applied Bayesian modeling and causal inference from incomplete-data perspectives},
	author = {Liu, Chuanhai},
	year = {2004},
	pages = {227--238},
	file = {[PDF] from purdue.edu:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/7EIVWHAK/Liu - 2004 - Robit regression a simple robust alternative to l.pdf:application/pdf}
}

@article{aranda-ordaz_two_1981,
	title = {On two families of transformations to additivity for binary response data},
	volume = {68},
	issn = {0006-3444, 1464-3510},
	url = {http://biomet.oxfordjournals.org/content/68/2/357},
	doi = {10.1093/biomet/68.2.357},
	abstract = {SUMMARY Two families of power transformations for probabilites are introduced to model symmetric and asymmetric departures from the logistic model. The aim is to provide, in a comprehensive way, a representation of alternative scales in terms of which to carry out the analysis of binary response data. Maximum likelihood methods are empolyed to estimate an appropriate transformation using GLIM. Tests for detection of symmetric and asymmetric departures are proposed.},
	language = {en},
	number = {2},
	urldate = {2015-02-22},
	journal = {Biometrika},
	author = {Aranda-Ordaz, Francisco J.},
	month = aug,
	year = {1981},
	pages = {357--363},
	file = {Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/2XJ52WJT/Aranda-Ordaz - 1981 - On two families of transformations to additivity f.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/NV49MR2H/357.html:text/html}
}

@article{guerrero_use_1982,
	title = {Use of the {Box}-{Cox} transformation with binary response models},
	volume = {69},
	issn = {0006-3444, 1464-3510},
	url = {http://biomet.oxfordjournals.org/content/69/2/309},
	doi = {10.1093/biomet/69.2.309},
	abstract = {SUMMARY The power transformation suggested by Box \& Cox (1964) is applied to the odds ratio to generalize the logistic model and to parameterize a certain type of lack of fit. Transformation of the design variable within the context of the dose-response problem is also considered.},
	language = {en},
	number = {2},
	urldate = {2015-02-22},
	journal = {Biometrika},
	author = {Guerrero, Victor M. and Johnson, Richard A.},
	month = aug,
	year = {1982},
	keywords = {Asymptotic normality, Consistency, Dose-response problem, Logistic model, Maximum likelihood estimation, Transformation},
	pages = {309--314},
	file = {Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/QDP485M6/Guerrero and Johnson - 1982 - Use of the Box-Cox transformation with binary resp.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/E78KBCEV/309.html:text/html}
}

@article{kim_binary_2002,
	title = {Binary {Regression} with a {Class} of {Skewed} t-{Link} {Models}},
	volume = {31},
	issn = {0361-0926},
	url = {http://dx.doi.org/10.1081/STA-120014917},
	doi = {10.1081/STA-120014917},
	abstract = {In this paper we propose a class of skewed t link models for analyzing binary response data with covariates. It is a class of asymmetric link models designed to improve the overall fit when commonly used symmetric links, such as the logit and probit links, do not provide the best fit available for a given binary response dataset. Introducing a skewed t distribution for the underlying latent variable, we develop the class of models. For the analysis of the models, a Bayesian and non-Bayesian methods are pursued using a Markov chain Monte Carlo (MCMC) sampling based approach. Necessary theories involved in modelling and computation are provided. Finally, a simulation study and a real data example are used to illustrate the proposed methodology.},
	number = {10},
	urldate = {2015-02-22},
	journal = {Communications in Statistics - Theory and Methods},
	author = {Kim, Hea-Jung},
	month = jan,
	year = {2002},
	pages = {1863--1886},
	file = {Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/X97A9AG6/Kim - 2002 - BINARY REGRESSION WITH A CLASS OF SKEWED t LINK MO.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/HUJ5KN2W/STA-120014917.html:text/html}
}

@incollection{capobianco_skewness_2002,
	title = {Skewness and {Fat} {Tails} in {Discrete} {Choice} {Models}},
	copyright = {{\textcopyright}2002 Physica-Verlag Heidelberg},
	isbn = {978-3-7908-1517-7 978-3-642-57489-4},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-57489-4_82},
	abstract = {In discrete choice models, the probability that the dependent variable will assume value 0 or 1 depends on a set of explanatory variables through a function F. In this paper we propose the class of skew Student t distribution as a function F in order to have a more flexible model that can simultaneously account for asymmetry and thick tails and such that probit and logit models can be considered as special cases. Two examples illustrate the performance of the proposed model.},
	language = {en},
	urldate = {2015-02-22},
	booktitle = {Compstat},
	publisher = {Physica-Verlag HD},
	author = {Capobianco, Rosa},
	editor = {H{\"a}rdle, Professor Dr Wolfgang and R{\"o}nz, Professor Dr Bernd},
	year = {2002},
	keywords = {Dichotomous models, fat tails, skewness, Statistics and Computing/Statistics Programs, Statistics for Business/Economics/Mathematical Finance/Insurance, Student t distribution},
	pages = {533--538},
	file = {Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/CJEWQSGD/Capobianco - 2002 - Skewness and Fat Tails in Discrete Choice Models.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/67UQBJRX/978-3-642-57489-4_82.html:text/html}
}

@article{manski_estimation_1977,
	title = {The {Estimation} of {Choice} {Probabilities} from {Choice} {Based} {Samples}},
	volume = {45},
	copyright = {Copyright {\textcopyright} 1977 The Econometric Society},
	issn = {0012-9682},
	url = {http://www.jstor.org/stable/1914121},
	doi = {10.2307/1914121},
	number = {8},
	urldate = {2015-03-08},
	journal = {Econometrica},
	author = {Manski, Charles F. and Lerman, Steven R.},
	month = nov,
	year = {1977},
	pages = {1977--1988},
	file = {JSTOR Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/6DI27QDD/Manski and Lerman - 1977 - The Estimation of Choice Probabilities from Choice.pdf:application/pdf}
}

@inproceedings{japkowicz_class_2000,
	title = {The {Class} {Imbalance} {Problem}: {Significance} and {Strategies}},
	shorttitle = {The {Class} {Imbalance} {Problem}},
	abstract = {Although the majority of conceptlearning systems previously designed usually assume that their training sets are well-balanced, this assumption is not necessarily correct. Indeed, there exist many domains for which one class is represented by a large number of examples while the other is represented by only a few. The purpose of this paper is 1) to demonstrate experimentally that, at least in the case of connectionist systems, class imbalances hinder the performance of standard classifiers and 2) to compare the performance of several approaches previously proposed to deal with the problem.  1 Introduction  As the field of machine learning makes a rapid transition from the status of "academic discipline " to that of "applied science", a myriad of new issues, not previously considered by the machine learning community, is now coming into light. One such issue is the class imbalance problem. The class imbalance problem corresponds to domains for which one class is represented by a large n...},
	booktitle = {In {Proceedings} of the 2000 {International} {Conference} on {Artificial} {Intelligence} ({ICAI}},
	author = {Japkowicz, Nathalie},
	year = {2000},
	pages = {111--117},
	file = {Citeseer - Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/P7E9MNSR/Japkowicz - 2000 - The Class Imbalance Problem Significance and Stra.pdf:application/pdf;Citeseer - Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/DGR2TNF5/summary.html:text/html}
}

@article{winkler_evaluating_1994,
	title = {Evaluating {Probabilities}: {Asymmetric} {Scoring} {Rules}},
	volume = {40},
	copyright = {Copyright {\textcopyright} 1994 INFORMS},
	issn = {0025-1909},
	shorttitle = {Evaluating {Probabilities}},
	url = {http://www.jstor.org/stable/2632926},
	abstract = {Proper scoring rules are overall evaluation measures that reward accurate probabilities. Specific rules encountered in the literature and used in practice are invariably symmetric in the sense that the expected score for a perfectly-calibrated probability assessor (or model generating probabilities) is minimized at a probability of one-half. A family of asymmetric scoring rules that provide better measures of the degree of skill inherent in the probabilities and render scores that are more comparable in different situations is developed here. One member of this family, a quadratic asymmetric rule, is applied to evaluate an extensive set of precipitation probability forecasts from the U.S. National Weather Service. Connections to previous characterizations of proper scoring rules are investigated, and some relevant issues pertaining to the design of specific asymmetric rules for particular inferential and decision-making problems are discussed briefly.},
	number = {11},
	urldate = {2015-03-10},
	journal = {Management Science},
	author = {Winkler, Robert L.},
	month = nov,
	year = {1994},
	pages = {1395--1405},
	file = {JSTOR Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/2VPRJCZE/Winkler - 1994 - Evaluating Probabilities Asymmetric Scoring Rules.pdf:application/pdf}
}

@article{cramer_predictive_1999,
	title = {Predictive {Performance} of the {Binary} {Logit} {Model} in {Unbalanced} {Samples}},
	volume = {48},
	copyright = {Royal Statistical Society 1999},
	issn = {1467-9884},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/1467-9884.00173/abstract},
	doi = {10.1111/1467-9884.00173},
	abstract = {In a binary logit analysis with unequal sample frequencies of the two outcomes the less frequent outcome always has lower estimated prediction probabilities than the other outcome. This effect is unavoidable, and its extent varies inversely with the fit of the model, as given by a new measure that follows naturally from the argument. Unbalanced samples with a poor fit are typical for survey analyses in the social sciences and epidemiology, and there the difference in prediction probabilities is most acute. It affects two common diagnostics: the within-sample {\textquoteleft}percentage cor-rectly predicted{\textquoteright} and the identification of outliers. Partial remedies are suggested.},
	language = {en},
	number = {1},
	urldate = {2015-03-28},
	journal = {Journal of the Royal Statistical Society: Series D (The Statistician)},
	author = {Cramer, J. S.},
	month = apr,
	year = {1999},
	keywords = {goodness of fit, Logistic regression, Predicted probabilities, Unequal sample proportions},
	pages = {85--94},
	file = {Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/6TRZVFXR/Cramer - 1999 - Predictive Performance of the Binary Logit Model i.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/9JRJ5TZX/abstract.html:text/html}
}

@incollection{czado_link_1992,
	series = {Lecture {Notes} in {Statistics}},
	title = {On {Link} {Selection} in {Generalized} {Linear} {Models}},
	copyright = {{\textcopyright}1992 Springer-Verlag New York},
	isbn = {978-0-387-97873-4 978-1-4612-2952-0},
	url = {http://link.springer.com/chapter/10.1007/978-1-4612-2952-0_10},
	abstract = {Generalized Linear Models (GLM) are extended to include the choice of a parametric link transformation family to improve fit over the standard GLM analysis in some data sets. However, the additional estimation of the link parameter results generally in higher estimated variances of the parameter estimates and numerical instability compared to the case when the correct link is known apriori. This paper extends two ideas developed for binary regression with parametric link (Czado [3]) {\textemdash} standardization and parameter orthogonality {\textemdash} to GLM{\textquoteright}s aimed at reducing the variance inflation and numerical instability. Simple standardized link families for GLM{\textquoteright}s are introduced and their usefulness are illustrated by an example.},
	language = {en},
	number = {78},
	urldate = {2015-04-05},
	booktitle = {Advances in {GLIM} and {Statistical} {Modelling}},
	publisher = {Springer New York},
	author = {Czado, Claudia},
	editor = {Fahrmeir, Ludwig and Francis, Brian and Gilchrist, Robert and Tutz, Gerhard},
	year = {1992},
	keywords = {Probability Theory and Stochastic Processes},
	pages = {60--65},
	file = {Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/AQABBFKR/Czado - 1992 - On Link Selection in Generalized Linear Models.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/7M69KR2R/978-1-4612-2952-0_10.html:text/html}
}

@article{golet_symmetric_2014,
	series = {Challenges and {Innovations} in {Management} and {Leadership} 12th {International} {Symposium} in {Management}},
	title = {Symmetric and {Asymmetric} {Binary} {Choice} {Models} for {Corporate} {Bankruptcy}},
	volume = {124},
	issn = {1877-0428},
	url = {http://www.sciencedirect.com/science/article/pii/S1877042814020357},
	doi = {10.1016/j.sbspro.2014.02.487},
	abstract = {Scientific literature aiming to explain and predict bankruptcy has been dominated, besides classical discriminant analysis, by symmetric binary choice models, also known as conditional probability models. The main research question that is addressed in this study is whether asymmetric binary choice models, based on extreme value theory, can explain bankruptcy better. The answer to this question is limited to the following testing context: corporate bankruptcy risk in the period of financial and economic turmoil, 2008-2012, is estimated starting from simple financial ratios available in Romania for the year 2007.},
	urldate = {2015-04-23},
	journal = {Procedia - Social and Behavioral Sciences},
	author = {Gole{\c t}, Ionu{\c t}},
	month = mar,
	year = {2014},
	keywords = {Bankruptcy, cloglog, economic crisis, extreme value theory, financial ratios, generalized extreme value regression, Logit, loglog, probit, ROC curve, scobit},
	pages = {282--291},
	file = {ScienceDirect Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/QDTKTF33/Gole{\c t} - 2014 - Symmetric and Asymmetric Binary Choice Models for .pdf:application/pdf;ScienceDirect Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/H87AZTG4/S1877042814020357.html:text/html}
}

@article{burr_cumulative_1942,
	title = {Cumulative {Frequency} {Functions}},
	volume = {13},
	copyright = {Copyright {\textcopyright} 1942 Institute of Mathematical Statistics},
	issn = {0003-4851},
	url = {http://www.jstor.org/stable/2235756},
	number = {2},
	urldate = {2015-07-04},
	journal = {The Annals of Mathematical Statistics},
	author = {Burr, Irving W.},
	month = jun,
	year = {1942},
	pages = {215--232},
	file = {JSTOR Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/3NU9AA25/Burr - 1942 - Cumulative Frequency Functions.pdf:application/pdf}
}

@article{weiss_mining_2004,
	title = {Mining with {Rarity}: {A} {Unifying} {Framework}},
	volume = {6},
	issn = {1931-0145},
	shorttitle = {Mining with {Rarity}},
	url = {http://doi.acm.org/10.1145/1007730.1007734},
	doi = {10.1145/1007730.1007734},
	abstract = {Rare objects are often of great interest and great value. Until recently, however, rarity has not received much attention in the context of data mining. Now, as increasingly complex real-world problems are addressed, rarity, and the related problem of imbalanced data, are taking center stage. This article discusses the role that rare classes and rare cases play in data mining. The problems that can result from these two forms of rarity are described in detail, as are methods for addressing these problems. These descriptions utilize examples from existing research. So that this article provides a good survey of the literature on rarity in data mining. This article also demonstrates that rare classes and rare cases are very similar phenomena---both forms of rarity are shown to cause similar problems during data mining and benefit from the same remediation methods.},
	number = {1},
	urldate = {2015-06-02},
	journal = {SIGKDD Explor. Newsl.},
	author = {Weiss, Gary M.},
	month = jun,
	year = {2004},
	keywords = {class imbalance, Cost-sensitive learning, inductive bias, rare cases, rare classes, Sampling, Small disjuncts},
	pages = {7--19},
	file = {ACM Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/Z947RXH8/Weiss - 2004 - Mining with Rarity A Unifying Framework.pdf:application/pdf}
}

@article{czado_parametric_1994,
	title = {Parametric link modification of both tails in binary regression},
	volume = {35},
	issn = {0932-5026, 1613-9798},
	url = {http://link.springer.com/article/10.1007/BF02926413},
	doi = {10.1007/BF02926413},
	abstract = {Common binary regression models such as logistic or probit regression have been extended to include parametric link transformation families. These binary regression models with parametric link are designed to avoid possible link misspecification and improve fit in some data sets. One and two parameter link families have been proposed in the literature (for a review see Stukel (1988)). However in real data examples published so far only one parameter link families have found to improve the fit significantly. This paper introduces a two parameter link family involving the modification of both tails of the link. An analysis based on computationally tractable Bayesian inference involving Monte Carlo sampling algorithms is presented extending earlier work of Czado (1992, 1993b). Finally, the usefulness of the two tailed link modification will be demonstrated in an example where single tail modification can be significantly improved upon by using a two tailed modification.},
	language = {en},
	number = {1},
	urldate = {2015-07-05},
	journal = {Statistical Papers},
	author = {Czado, Claudia},
	month = dec,
	year = {1994},
	keywords = {Bayesian inference, binary regression, Economic Theory, Gibbs sampler, Markov chain Monte Carlo methods, maximum likelihood, Metropolis algorithm, Operations Research/Decision Theory, parametric link transformation, Probability Theory and Stochastic Processes, rejection sampling, Statistics for Business/Economics/Mathematical Finance/Insurance},
	pages = {189--201},
	file = {Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/VKEPXPMA/Czado - 1994 - Parametric link modification of both tails in bina.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/UFR6ZVX7/BF02926413.html:text/html}
}

@article{zhang_developing_2011,
	title = {Developing an integrated scobit-based activity participation and time allocation model to explore influence of childcare on women{\textquoteright}s time use behaviour},
	volume = {39},
	issn = {0049-4488, 1572-9435},
	url = {http://link.springer.com/article/10.1007/s11116-011-9321-5},
	doi = {10.1007/s11116-011-9321-5},
	abstract = {Focusing on the influence of childcare on women{\textquoteright}s time use behaviour, this paper develops an integrated model of activity participation and time allocation, where the former is represented based on a scobit model and the latter based on a multi-linear utility function under the utility-maximizing principle. The integration of the scobit model with the time allocation model is done by applying Lee{\textquoteright}s transformation. Especially, the scobit model is adopted to relax the assumption, made in the Logit or Probit model, that individuals having indifferent preferences over participation and non-participation are most sensitive to changes in explanatory variables. Using a large-scale time use data (66,839 persons) collected in Japan, the effectiveness of the proposed integrated model is empirically confirmed. It is revealed that the probabilities of participating in compulsory-contracted activities and discretionary activities with the highest sensitivity to changes in explanatory variables are 65 and 81\%, respectively. Variances of social childcare variables explain about half of the total variance of the time use for discretionary activities; however, for compulsory-contracted activities, social childcare variables explain only less than 1\% of the total variance of activity participation and less than 10\% of total variable of time allocation.},
	language = {en},
	number = {1},
	urldate = {2015-07-07},
	journal = {Transportation},
	author = {Zhang, Junyi and Xu, Lili and Fujiwara, Akimasa},
	month = jan,
	year = {2011},
	keywords = {Activity participation, Childcare, Economic Geography, Engineering Economics, Organization, Logistics, Marketing, Innovation/Technology Management, Japan, Regional/Spatial Science, Scobit model, Time allocation, Women},
	pages = {125--149},
	file = {Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/NUW5MIXH/Zhang et al. - 2011 - Developing an integrated scobit-based activity par.pdf:application/pdf;Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/ZBCWK5KB/Zhang et al. - 2011 - Developing an integrated scobit-based activity par.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/236Z7K5N/s11116-011-9321-5.html:text/html;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/V9N6DX3G/s11116-011-9321-5.html:text/html}
}

@article{wu_analysis_2012,
	title = {Analysis of {Tourism} {Generation} {Incorporating} the {Influence} of {Constraints} {Based} on a {Scobit} {Model}},
	volume = {2},
	doi = {10.11175/eastsats.2.19},
	abstract = {Tourism generation is one of the most important aspects but it remains as an under-researched area in tourism demand forecasting and relevant behavior analysis. This study analyzes individual's decision on whether to go on vacation or not. First, a number of constraints that prohibit tourism participation are explored. Second, individual's choice of tourism participation is studied based on a Scobit model, which includes a skewness parameter to relax the assumption made in binary logit model that the sensitivity of individuals to changes in explanatory variables is highest for those who have indifferent preferences over participation and non-participation. We also introduce the tourism constraint components into the model based on the theoretical consideration in the existing literature. The empirical application is conducted using the data stemmed from a web survey conducted in Japan in 2010. Using this data the impacts of several attributes on participation decisions in tourism are investigated.},
	number = {1},
	journal = {Asian Transport Studies},
	author = {Wu, Lingling and Zhang, Junyi and Fujiwara, Akimasa and Chikaraishi, Makoto},
	year = {2012},
	keywords = {Constraints, Scobit model, skewness, Tourism generation},
	pages = {19--33},
	file = {Jstage - Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/N7ZMSE88/Wu et al. - 2012 - Analysis of Tourism Generation Incorporating the I.pdf:application/pdf}
}

@article{zhang_scobit-based_2010,
	title = {Scobit-{Based} {Panel} {Analysis} of {Multitasking} {Behavior} of {Public} {Transport} {Users}},
	volume = {2157},
	issn = {0361-1981},
	url = {http://trrjournalonline.trb.org/doi/abs/10.3141/2157-06},
	doi = {10.3141/2157-06},
	urldate = {2015-07-07},
	journal = {Transportation Research Record: Journal of the Transportation Research Board},
	author = {Zhang, Junyi and Timmermans, Harry},
	month = dec,
	year = {2010},
	pages = {46--53},
	file = {Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/ASTISIQJ/Zhang and Timmermans - 2010 - Scobit-Based Panel Analysis of Multitasking Behavi.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/GSAJKVT6/2157-06.html:text/html}
}

@book{ben-akiva_discrete_1985,
	title = {Discrete {Choice} {Analysis}: {Theory} and {Application} to {Travel} {Demand}},
	isbn = {978-0-262-02217-0},
	shorttitle = {Discrete {Choice} {Analysis}},
	abstract = {The methods of discrete choice analysis and their applications in the modelling of transportation systems constitute a comparatively new field that has largely evolved over the past 15 years. Since its inception, however, the field has developed rapidly, and this is the first text and reference work to cover the material systematically, bringing together the scattered and often inaccessible results for graduate students and professionals. Discrete Choice Analysis presents these results in such a way that they are fully accessible to the range of students and professionals who are involved in modelling demand and consumer behavior in general or specifically in transportation - whether from the point of view of the design of transit systems, urban and transport economics, public policy, operations research, or systems management and planning. The introductory chapter presents the background of discrete choice analysis and context of transportation demand forecasting. Subsequent chapters cover, among other topics, the theories of individual choice behavior, binary and multinomial choice models, aggregate forecasting techniques, estimation methods, tests used in the process of model development, sampling theory, the nested-logit model, and systems of models. Moshe Ben-Akiva and Steven R. Lerman are both faculty members of the Civil Engineering Department at MIT and affiliated with its Center for Transportation Studies. Discrete Choice Analysis is ninth in the MIT Press Series in Transportation Studies, edited by Marvin Manheim.},
	language = {en},
	publisher = {MIT Press},
	author = {Ben-Akiva, Moshe E. and Lerman, Steven R.},
	year = {1985},
	keywords = {Architecture / Urban \& Land Use Planning, Business \& Economics / Commerce}
}

@book{breslow_statistical_1987,
	title = {Statistical methods in cancer research},
	volume = {2},
	url = {http://w2.iarc.fr/en/publications/pdfs-online/stat/sp32/SP32_vol1-0.pdf},
	urldate = {2015-07-07},
	publisher = {International Agency for Research on Cancer Lyon},
	author = {Breslow, Norman E. and Day, Nicholas E. and {others}},
	year = {1987},
	file = {[PDF] from iarc.fr:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/I7ZPCMD9/Breslow et al. - 1987 - Statistical methods in cancer research.pdf:application/pdf;The Analysis of Case Control Studies.pdf:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/4X89ST98/The Analysis of Case Control Studies.pdf:application/pdf}
}

@techreport{sfmta_2012_2012,
	title = {2012 {San} {Francisco} {State} of {Cycling} {Report}},
	url = {http://archives.sfmta.com/cms/rbikes/documents/2012StateofCyclingReport8_9_12.pdf},
	urldate = {2015-07-28},
	institution = {San Francisco Municipal Transportation Agency},
	author = {SFMTA},
	month = sep,
	year = {2012},
	pages = {28}
}

@article{ewing_travel_2001,
	title = {Travel and the {Built} {Environment}: {A} {Synthesis}},
	volume = {1780},
	issn = {0361-1981},
	shorttitle = {Travel and the {Built} {Environment}},
	url = {http://trrjournalonline.trb.org/doi/abs/10.3141/1780-10},
	doi = {10.3141/1780-10},
	abstract = {The potential to moderate travel demand through changes in the built environment is the subject of more than 50 recent empirical studies. The majority of recent studies are summarized. Elasticities of travel demand with respect to density, diversity, design, and regional accessibility are then derived from selected studies. These elasticity values may be useful in travel forecasting and sketch planning and have already been incorporated into one sketch planning tool, the Environmental Protection Agency's Smart Growth Index model. In weighing the evidence, what can be said, with a degree of certainty, about the effects of built environments on key transportation "outcome" variables: trip frequency, trip length, mode choice, and composite measures of travel demand, vehicle miles traveled (VMT) and vehicle hours traveled (VHT)? Trip frequencies have attracted considerable academic interest of late. They appear to be primarily a function of socioeconomic characteristics of travelers and secondarily a function of the built environment. Trip lengths have received relatively little attention, which may account for the various degrees of importance attributed to the built environment in recent studies. Trip lengths are primarily a function of the built environment and secondarily a function of socioeconomic characteristics. Mode choices have received the most intensive study over the decades. Mode choices depend on both the built environment and socioeconomics (although they probably depend more on the latter). Studies of overall VMT or VHT find the built environment to be much more significant, a product of the differential trip lengths that factor into calculations of VMT and VHT.},
	urldate = {2016-01-03},
	journal = {Transportation Research Record: Journal of the Transportation Research Board},
	author = {Ewing, Reid and Cervero, Robert},
	month = jan,
	year = {2001},
	pages = {87--114},
	file = {Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/V5VPHJCX/Ewing and Cervero - 2001 - Travel and the Built Environment A Synthesis.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/CD5S22AN/1780-10.html:text/html}
}

@article{efron_improvements_1997,
	title = {Improvements on {Cross}-{Validation}: {The} .632+ {Bootstrap} {Method}},
	volume = {92},
	issn = {0162-1459},
	shorttitle = {Improvements on {Cross}-{Validation}},
	url = {http://www.jstor.org/stable/2965703},
	doi = {10.2307/2965703},
	abstract = {A training set of data has been used to construct a rule for predicting future responses. What is the error rate of this rule? This is an important question both for comparing models and for assessing a final selected model. The traditional answer to this question is given by cross-validation. The cross-validation estimate of prediction error is nearly unbiased but can be highly variable. Here we discuss bootstrap estimates of prediction error, which can be thought of as smoothed versions of cross-validation. We show that a particular bootstrap method, the .632+ rule, substantially outperforms cross-validation in a catalog of 24 simulation experiments. Besides providing point estimates, we also consider estimating the variability of an error rate estimate. All of the results here are nonparametric and apply to any possible prediction rule; however, we study only classification problems with 0-1 loss in detail. Our simulations include "smooth" prediction rules like Fisher's linear discriminant function and unsmooth ones like nearest neighbors.},
	number = {438},
	urldate = {2016-01-03},
	journal = {Journal of the American Statistical Association},
	author = {Efron, Bradley and Tibshirani, Robert},
	year = {1997},
	pages = {548--560},
	file = {JSTOR Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/V8R58XEP/Efron and Tibshirani - 1997 - Improvements on Cross-Validation The .632+ Bootst.pdf:application/pdf}
}

@article{mattsson_extreme_2014,
	title = {Extreme values, invariance and choice probabilities},
	volume = {59},
	issn = {0191-2615},
	url = {http://www.sciencedirect.com/science/article/pii/S0191261513001987},
	doi = {10.1016/j.trb.2013.10.014},
	abstract = {Since the pioneering work of McFadden (1974), discrete choice random-utility models have become work horses in many areas in transportation analysis and economics. In these models, the random variables enter additively or multiplicatively and the noise distributions take a particular parametric form. We show that the same qualitative results, with closed-form choice probabilities, can be obtained for a wide class of distributions without such specifications. This class generalizes the statistically independent distributions where any two c.d.f.:s are powers of each others to a class that allows for statistical dependence, in a way analogous to how the independent distributions in the MNL models were generalized into the subclass of MEV distributions that generates the GEV choice models. We show that this generalization is sufficient, and under statistical independence also necessary, for the following invariance property: all conditional random variables, when conditioning upon a certain alternative having been chosen, are identically distributed. While some of these results have been published earlier, we place them in a general unified framework that allows us to extend several of the results and to provide proofs that are simpler, more direct and transparent. Well-known results are obtained as special cases, and we characterize the Gumbel, Fr{\'e}chet and Weibull distributions.},
	urldate = {2016-01-03},
	journal = {Transportation Research Part B: Methodological},
	author = {Mattsson, Lars-G{\"o}ran and Weibull, J{\"o}rgen W. and Lindberg, Per Olov},
	month = jan,
	year = {2014},
	keywords = {Choice probabilities, Discrete choice, Extreme values, Invariance, Random utility},
	pages = {81--95},
	file = {ScienceDirect Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/SU4AKUSS/Mattsson et al. - 2014 - Extreme values, invariance and choice probabilitie.pdf:application/pdf;ScienceDirect Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/AMRS94D8/Mattsson et al. - 2014 - Extreme values, invariance and choice probabilitie.pdf:application/pdf;ScienceDirect Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/RW5AN3SD/S0191261513001987.html:text/html;ScienceDirect Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/3TDE9GJR/S0191261513001987.html:text/html}
}

@article{castillo_closed_2008,
	title = {Closed form expressions for choice probabilities in the {Weibull} case},
	volume = {42},
	issn = {0191-2615},
	url = {http://www.sciencedirect.com/science/article/pii/S019126150700077X},
	doi = {10.1016/j.trb.2007.08.002},
	abstract = {For a probabilistic discrete choice model with independent reversed Gumbel distributed random costs, closed form expressions for the choice probabilities are known under the assumption that the variance is the same for all choice alternatives. This assumption is highly disputable in many cases in reality. In this paper, closed form expressions for the choice probabilities are derived for the case of independent Weibull distributed random costs. It is then necessary to assume that the variance of the Weibull distributed cost is a specific increasing function of its mean, which, however, may be a more natural assumption in many cases. The theoretical results are explained and exemplified in terms of the familiar stochastic user equilibrium (SUE) traffic assignment model.},
	number = {4},
	urldate = {2016-01-03},
	journal = {Transportation Research Part B: Methodological},
	author = {Castillo, Enrique and Men{\'e}ndez, Jos{\'e} Mar{\'i}a and Jim{\'e}nez, Pilar and Rivas, Ana},
	month = may,
	year = {2008},
	keywords = {MNL model, Weibull SUE models},
	pages = {373--380},
	file = {ScienceDirect Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/7NMSS33A/Castillo et al. - 2008 - Closed form expressions for choice probabilities i.pdf:application/pdf;ScienceDirect Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/TZW3HD5E/Castillo et al. - 2008 - Closed form expressions for choice probabilities i.pdf:application/pdf;ScienceDirect Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/SIME3GH5/S019126150700077X.html:text/html;ScienceDirect Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/QRE5HK73/S019126150700077X.html:text/html}
}

@article{fosgerau_discrete_2009,
	title = {Discrete choice models with multiplicative error terms},
	volume = {43},
	issn = {0191-2615},
	url = {http://www.sciencedirect.com/science/article/pii/S0191261508001215},
	doi = {10.1016/j.trb.2008.10.004},
	abstract = {The conditional indirect utility of many random utility maximization (RUM) discrete choice models is specified as a sum of an index V depending on observables and an independent random term $\varepsilon$ . In general, the universe of RUM consistent models is much larger, even fixing some specification of V due to theoretical and practical considerations. In this paper, we explore an alternative RUM model where the summation of V and $\varepsilon$ is replaced by multiplication. This is consistent with the notion that choice makers may sometimes evaluate relative differences in V between alternatives rather than absolute differences. We develop some properties of this type of model and show that in several cases the change from an additive to a multiplicative formulation, maintaining a specification of V, may lead to a large improvement in fit, sometimes larger than that gained from introducing random coefficients in V.},
	number = {5},
	urldate = {2016-01-03},
	journal = {Transportation Research Part B: Methodological},
	author = {Fosgerau, Mogens and Bierlaire, Michel},
	month = jun,
	year = {2009},
	keywords = {Discrete choice, Heteroscedasticity, Multiplicative specification, Multivariate extreme value, Random scale},
	pages = {494--505},
	file = {ScienceDirect Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/FMH2ITKZ/Fosgerau and Bierlaire - 2009 - Discrete choice models with multiplicative error t.pdf:application/pdf;ScienceDirect Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/95BPE4JJ/S0191261508001215.html:text/html}
}

@article{li_multinomial_2011,
	title = {The multinomial logit model revisited: {A} semi-parametric approach in discrete choice analysis},
	volume = {45},
	issn = {0191-2615},
	shorttitle = {The multinomial logit model revisited},
	url = {http://www.sciencedirect.com/science/article/pii/S0191261510001190},
	doi = {10.1016/j.trb.2010.09.007},
	abstract = {The multinomial logit model in discrete choice analysis is widely used in transport research. It has long been known that the Gumbel distribution forms the basis of the multinomial logit model. Although the Gumbel distribution is a good approximation in some applications such as route choice problems, it is chosen mainly for mathematical convenience. This can be restrictive in many other scenarios in practice. In this paper we show that the assumption of the Gumbel distribution can be substantially relaxed to include a large class of distributions that is stable with respect to the minimum operation. The distributions in the class allow heteroscedastic variances. We then seek a transformation that stabilizes the heteroscedastic variances. We show that this leads to a semi-parametric choice model which links the linear combination of travel-related attributes to the choice probabilities via an unknown sensitivity function. This sensitivity function reflects the degree of travelers{\textquoteright} sensitivity to the changes in the combined travel cost. The estimation of the semi-parametric choice model is also investigated and empirical studies are used to illustrate the developed method.},
	number = {3},
	urldate = {2016-01-03},
	journal = {Transportation Research Part B: Methodological},
	author = {Li, Baibing},
	month = mar,
	year = {2011},
	keywords = {Discrete choice model, Gumbel distribution, Multinomial logit model, Semi-parametric model, Variance stabilization},
	pages = {461--473},
	file = {ScienceDirect Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/M5HWN78P/Li - 2011 - The multinomial logit model revisited A semi-para.pdf:application/pdf;ScienceDirect Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/WQJU3932/S0191261510001190.html:text/html}
}

@article{hauser_disjunctions_2010,
	title = {Disjunctions of {Conjunctions}, {Cognitive} {Simplicity}, and {Consideration} {Sets}},
	volume = {47},
	issn = {0022-2437},
	url = {http://journals.ama.org/doi/abs/10.1509/jmkr.47.3.485},
	doi = {10.1509/jmkr.47.3.485},
	abstract = {The authors test methods, based on cognitively simple decision rules, that predict which products consumers select for their consideration sets. Drawing on qualitative research, the authors propose disjunctions-of-conjunctions (DOC) decision rules that generalize well-studied decision models, such as disjunctive, conjunctive, lexicographic, and subset conjunctive rules. They propose two machine-learning methods to estimate cognitively simple DOC rules. They observe consumers' consideration sets for global positioning systems for both calibration and validation data. They compare the proposed methods with both machine-learning and hierarchical Bayes methods, each based on five extant compensatory and noncompensatory rules. For the validation data, the cognitively simple DOC-based methods predict better than the ten benchmark methods on an information theoretic measure and on hit rates. The results are robust with respect to format by which consideration is measured, sample, and presentation of profiles. The article closes with an illustration of how DOC-based rules can affect managerial decisions.},
	number = {3},
	urldate = {2016-01-03},
	journal = {Journal of Marketing Research},
	author = {Hauser, John R and Toubia, Olivier and Evgeniou, Theodoros and Befurt, Rene and Dzyabura, Daria},
	month = jun,
	year = {2010},
	pages = {485--496},
	file = {document(1).pdf:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/5UE9AN6D/document(1).pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/ND3XJUQR/jmkr.47.3.html:text/html}
}

@misc{federal_highway_administration_bicycle_2003,
	title = {Bicycle and {Pedestrian} {Transportation} {Planning} {Guidance} - {Guidance} - {Bicycle} and {Pedestrian} {Program} - {Environment} - {FHWA}},
	url = {http://www.fhwa.dot.gov/environment/bicycle_pedestrian/guidance/inter.cfm#i2},
	urldate = {2016-01-19},
	author = {{Federal Highway Administration}},
	month = aug,
	year = {2003},
	file = {Bicycle and Pedestrian Transportation Planning Guidance - Guidance - Bicycle and Pedestrian Program - Environment - FHWA:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/7XQXAKI9/inter.html:text/html}
}

@article{mcfadden_conditional_1972,
	title = {{Conditional} {Logit} {Analysis} {of} {Qualitative} {Choice} {Behavior}},
	url = {http://trid.trb.org/view.aspx?id=235187},
	number = {199},
	urldate = {2016-01-03},
	journal = {Working Paper Institute of Urban and Regional Development},
	author = {McFadden, Daniel},
	year = {1972},
	file = {Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/RWR9F4BP/view.html:text/html;zarembka.pdf:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/VXV63T27/zarembka.pdf:application/pdf}
}

@book{horowitz_semiparametric_2010,
	title = {Semiparametric and {Nonparametric} {Methods} in {Econometrics}},
	isbn = {978-0-387-92870-8},
	abstract = {Standard methods for estimating empirical models in economics and many other fields rely on strong assumptions about functional forms and the distributions of unobserved random variables. Often, it is assumed that functions of interest are linear or that unobserved random variables are normally distributed. Such assumptions simplify estimation and statistical inference but are rarely justified by economic theory or other a priori considerations. Inference based on convenient but incorrect assumptions about functional forms and distributions can be highly misleading. Nonparametric and semiparametric statistical methods provide a way to reduce the strength of the assumptions required for estimation and inference, thereby reducing the opportunities for obtaining misleading results. These methods are applicable to a wide variety of estimation problems in empirical economics and other fields, and they are being used in applied research with increasing frequency. The literature on nonparametric and semiparametric estimation is large and highly technical. This book presents the main ideas underlying a variety of nonparametric and semiparametric methods. It is accessible to graduate students and applied researchers who are familiar with econometric and statistical theory at the level taught in graduate-level courses in leading universities. The book emphasizes ideas instead of technical details and provides as intuitive an exposition as possible. Empirical examples illustrate the methods that are presented. This book updates and greatly expands the author{\textquoteright}s previous book on semiparametric methods in econometrics. Nearly half of the material is new.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Horowitz, Joel L.},
	month = jul,
	year = {2010},
	keywords = {Business \& Economics / Econometrics, Business \& Economics / General, Business \& Economics / Statistics, Mathematics / Probability \& Statistics / General, Mathematics / Probability \& Statistics / Stochastic Processes},
	file = {[PDF] from birs.ca:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/2B463D9Q/Horowitz - 2009 - Semiparametric and nonparametric methods in econom.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/6SQ95BII/bok%3A978-0-387-92870-8.pdf:application/pdf}
}

@article{hardle_semiparametric_1997,
	title = {Semiparametric single index versus fixed link function modelling},
	volume = {25},
	url = {http://projecteuclid.org/euclid.aos/1034276627},
	number = {1},
	urldate = {2016-01-03},
	journal = {The Annals of Statistics},
	author = {H{\"a}rdle, Wolfgang and Spokoiny, V. and Sperlich, Stefan and {others}},
	year = {1997},
	pages = {212--243},
	file = {00b7d53b4732eebda0000000pdf:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/J8IIDPEX/00b7d53b4732eebda0000000pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/TFVK4NPQ/1034276627.html:text/html}
}

@article{zou_new_2008,
	title = {New {Multicategory} {Boosting} {Algorithms} {Based} on {Multicategory} {Fisher}-{Consistent} {Losses}},
	volume = {2},
	issn = {1932-6157},
	url = {http://www.jstor.org/stable/30245136},
	abstract = {Fisher-consistent loss functions play a fundamental role in the construction of successful binary margin-based classifiers. In this paper we establish the Fisher-consistency condition for multicategory classification problems. Our approach uses the margin vector concept which can be regarded as a multicategory generalization of the binary margin. We characterize a wide class of smooth convex loss functions that are Fisher-consistent for multicategory classification. We then consider using the margin-vector-based loss functions to derive multicategory boosting algorithms. In particular, we derive two new multicategory boosting algorithms by using the exponential and logistic regression losses.},
	number = {4},
	urldate = {2016-01-03},
	journal = {The Annals of Applied Statistics},
	author = {Zou, Hui and Zhu, Ji and Hastie, Trevor},
	year = {2008},
	pages = {1290--1306},
	file = {JSTOR Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/97F5ZJWZ/Zou et al. - 2008 - New Multicategory Boosting Algorithms Based on Mul.pdf:application/pdf}
}

@incollection{masnadi-shirazi_variable_2010,
	title = {Variable margin losses for classifier design},
	url = {http://papers.nips.cc/paper/4024-variable-margin-losses-for-classifier-design.pdf},
	urldate = {2016-01-03},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 23},
	publisher = {Curran Associates, Inc.},
	author = {Masnadi-shirazi, Hamed and Vasconcelos, Nuno},
	editor = {Lafferty, J. D. and Williams, C. K. I. and Shawe-Taylor, J. and Zemel, R. S. and Culotta, A.},
	year = {2010},
	pages = {1576--1584},
	file = {NIPS Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/3B2Z28EG/Masnadi-shirazi and Vasconcelos - 2010 - Variable margin losses for classifier design.pdf:application/pdf;NIPS Snapshort:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/NT97PBAC/4024-variable-margin-losses-for-classifier-design.html:text/html}
}

@article{nakayama_unified_2015,
	series = {{ISTTT} 21 for the year 2015SI: {ISTTT}21},
	title = {Unified closed-form expression of logit and weibit and its extension to a transportation network equilibrium assignment},
	volume = {81, Part 3},
	issn = {0191-2615},
	url = {http://www.sciencedirect.com/science/article/pii/S0191261515001666},
	doi = {10.1016/j.trb.2015.07.019},
	abstract = {This study proposes a generalized multinomial logit model that allows heteroscedastic variance and flexible utility function shape. The novelty of our approach is that the model is theoretically derived by applying a generalized extreme-value distribution to the random component of utility, while retaining its closed-form expression. In addition, the weibit model, in which the random utility is assumed to follow the Weibull distribution, is a special case of the proposed model. This is achieved by utilizing the q-generalization method developed in Tsallis statistics. Then, our generalized logit model is incorporated into a transportation network equilibrium model. The network equilibrium model with a generalized logit route choice is formulated as an optimization problem for uncongested networks. The objective function includes Tsallis entropy, a type of generalized entropy. The generalization of the Gumbel and Weibull distributions, logit and weibit models, and network equilibrium model are formulated within a unified framework with q-generalization or Tsallis statistics.},
	urldate = {2016-04-11},
	journal = {Transportation Research Part B: Methodological},
	author = {Nakayama, Shoichiro and Chikaraishi, Makoto},
	month = nov,
	year = {2015},
	keywords = {closed-form expression, Logit, Transportation network equilibrium assignment, Tsallis entropy, weibit},
	pages = {672--685},
	file = {ScienceDirect Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/KVAUNV8N/Nakayama and Chikaraishi - 2015 - Unified closed-form expression of logit and weibit.pdf:application/pdf;ScienceDirect Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/ICV9GQ4J/S0191261515001666.html:text/html}
}

@article{guo_effect_2007,
	title = {Effect of the {Built} {Environment} on {Motorized} and {Nonmotorized} {Trip} {Making}: {Substitutive}, {Complementary}, or {Synergistic}?},
	volume = {2010},
	issn = {0361-1981},
	shorttitle = {Effect of the {Built} {Environment} on {Motorized} and {Nonmotorized} {Trip} {Making}},
	url = {http://trrjournalonline.trb.org/doi/10.3141/2010-01},
	doi = {10.3141/2010-01},
	abstract = {It has become well recognized that nonmotorized transportation is beneficial to a community's health as well as its transportation system performance. In view of the limited public resources available for improving public health and transportation, the present study aims to (a) assess the expected impact of built environment improvements on the substitutive, complementary, or synergistic use of motorized and nonmotorized modes and (b) examine how the effects of built environment improvements differ for different population groups and for different travel purposes. The bivariate ordered probit models estimated in this study suggest that few built environment factors lead to the substitution of motorized mode use by nonmotorized mode use. Instead, factors such as increased bikeway density and street network connectivity have the potential to promote more nonmotorized travel to supplement individuals' existing motorized trips. Meanwhile, the heterogeneity found in individuals' responsiveness to built environment factors indicates that built environment improvements need to be sensitive to local residents' characteristics.},
	urldate = {2016-01-03},
	journal = {Transportation Research Record: Journal of the Transportation Research Board},
	author = {Guo, Jessica and Bhat, Chandra and Copperman, Rachel},
	month = jan,
	year = {2007},
	pages = {1--11},
	file = {Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/N72BDEVM/Guo et al. - 2007 - Effect of the Built Environment on Motorized and N.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/5NDUNZ3H/2010-01.html:text/html}
}

@article{feroz_importance_2013,
	title = {Importance {Nested} {Sampling} and the {MultiNest} {Algorithm}},
	url = {http://arxiv.org/abs/1306.2144},
	abstract = {Bayesian inference involves two main computational challenges. First, in estimating the parameters of some model for the data, the posterior distribution may well be highly multi-modal: a regime in which the convergence to stationarity of traditional Markov Chain Monte Carlo (MCMC) techniques becomes incredibly slow. Second, in selecting between a set of competing models the necessary estimation of the Bayesian evidence for each is, by definition, a (possibly high-dimensional) integration over the entire parameter space; again this can be a daunting computational task, although new Monte Carlo (MC) integration algorithms offer solutions of ever increasing efficiency. Nested sampling (NS) is one such contemporary MC strategy targeted at calculation of the Bayesian evidence, but which also enables posterior inference as a by-product, thereby allowing simultaneous parameter estimation and model selection. The widely-used MultiNest algorithm presents a particularly efficient implementation of the NS technique for multi-modal posteriors. In this paper we discuss importance nested sampling (INS), an alternative summation of the MultiNest draws, which can calculate the Bayesian evidence at up to an order of magnitude higher accuracy than `vanilla' NS with no change in the way MultiNest explores the parameter space. This is accomplished by treating as a (pseudo-)importance sample the totality of points collected by MultiNest, including those previously discarded under the constrained likelihood sampling of the NS algorithm. We apply this technique to several challenging test problems and compare the accuracy of Bayesian evidences obtained with INS against those from vanilla NS.},
	urldate = {2016-01-03},
	journal = {arXiv:1306.2144 [astro-ph, physics:physics, stat]},
	author = {Feroz, F. and Hobson, M. P. and Cameron, E. and Pettitt, A. N.},
	month = jun,
	year = {2013},
	note = {arXiv: 1306.2144},
	keywords = {Astrophysics - Instrumentation and Methods for Astrophysics, Physics - Data Analysis, Statistics and Probability, Statistics - Computation},
	file = {arXiv\:1306.2144 PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/IGM5WT5F/Feroz et al. - 2013 - Importance Nested Sampling and the MultiNest Algor.pdf:application/pdf;arXiv.org Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/J42DZBRF/1306.html:text/html}
}

@article{buchner_x-ray_2014,
	title = {X-ray spectral modelling of the {AGN} obscuring region in the {CDFS}: {Bayesian} model selection and catalogue},
	volume = {564},
	issn = {0004-6361, 1432-0746},
	shorttitle = {X-ray spectral modelling of the {AGN} obscuring region in the {CDFS}},
	url = {http://www.aanda.org/10.1051/0004-6361/201322971},
	doi = {10.1051/0004-6361/201322971},
	urldate = {2016-01-03},
	journal = {Astronomy \& Astrophysics},
	author = {Buchner, J. and Georgakakis, A. and Nandra, K. and Hsu, L. and Rangel, C. and Brightman, M. and Merloni, A. and Salvato, M. and Donley, J. and Kocevski, D.},
	month = apr,
	year = {2014},
	pages = {A125}
}

@article{feroz_comment_2010,
	title = {Comment on "{Bayesian} evidence: can we beat {MultiNest} using traditional {MCMC} methods", by {Rutger} van {Haasteren} ({arXiv}:0911.2150)},
	shorttitle = {Comment on "{Bayesian} evidence},
	url = {http://arxiv.org/abs/1001.0719},
	abstract = {In arXiv:0911.2150, Rutger van Haasteren seeks to criticize the nested sampling algorithm for Bayesian data analysis in general and its MultiNest implementation in particular. He introduces a new method for evidence evaluation based on the idea of Voronoi tessellation and requiring samples from the posterior distribution obtained through MCMC based methods. He compares its accuracy and efficiency with MultiNest, concluding that it outperforms MultiNest in several cases. This comparison is completely unfair since the proposed method can not perform the complete Bayesian data analysis including posterior exploration and evidence evaluation on its own while MultiNest allows one to perform Bayesian data analysis end to end. Furthermore, their criticism of nested sampling (and in turn MultiNest) is based on a few conceptual misunderstandings of the algorithm. Here we seek to set the record straight.},
	urldate = {2016-01-03},
	journal = {arXiv:1001.0719 [astro-ph, physics:gr-qc, physics:physics]},
	author = {Feroz, F. and Hobson, M. P. and Trotta, R.},
	month = jan,
	year = {2010},
	note = {arXiv: 1001.0719},
	keywords = {Astrophysics - Instrumentation and Methods for Astrophysics, General Relativity and Quantum Cosmology, Physics - Data Analysis, Statistics and Probability},
	file = {arXiv\:1001.0719 PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/B3R5W59D/Feroz et al. - 2010 - Comment on Bayesian evidence can we beat MultiNe.pdf:application/pdf;arXiv.org Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/SVKAHFFT/1001.html:text/html}
}

@incollection{kok_assortment_2009,
	title = {Assortment planning: {Review} of literature and industry practice},
	shorttitle = {Assortment planning},
	url = {http://link.springer.com/10.1007/978-0-387-78902-6_6},
	urldate = {2016-01-03},
	booktitle = {Retail supply chain management},
	publisher = {Springer},
	author = {K{\"o}k, A. G{\"u}rhan and Fisher, Marshall L. and Vaidyanathan, Ramnath},
	year = {2009},
	pages = {99--153},
	file = {[PDF] from googlecode.com:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/83JKAMR2/K{\"o}k et al. - 2009 - Assortment planning Review of literature and indu.pdf:application/pdf;[PDF] from googlecode.com:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/DVTFXK4W/K{\"o}k et al. - 2009 - Assortment planning Review of literature and indu.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/75WT4SJA/10.html:text/html;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/ZB2GF75R/10.html:text/html}
}

@article{gallego_multiproduct_2014,
	title = {Multiproduct {Price} {Optimization} and {Competition} {Under} the {Nested} {Logit} {Model} with {Product}-{Differentiated} {Price} {Sensitivities}},
	volume = {62},
	issn = {0030-364X},
	url = {http://pubsonline.informs.org/doi/abs/10.1287/opre.2013.1249},
	doi = {10.1287/opre.2013.1249},
	abstract = {We study firms that sell multiple substitutable products and customers whose purchase behavior follows a nested logit model, of which the multinomial logit model is a special case. Customers make purchasing decisions sequentially under the nested logit model: they first select a nest of products and subsequently purchase one within the selected nest. We consider the multiproduct pricing problem under the general nested logit model with product-differentiated price sensitivities and arbitrary nest coefficients. We show that the adjusted markup, defined as price minus cost minus the reciprocal of price sensitivity, is constant for all the products within a nest at optimality. This reduces the problem's dimension to a single variable per nest. We also show that the adjusted nest-level markup is nest invariant for all the nests, which further reduces the problem to maximizing a single-variable unimodal function under mild conditions. We also use this result to simplify the oligopolistic multiproduct price competition and characterize the Nash equilibrium. We also consider more general attraction functions that include the linear utility and the multiplicative competitive interaction models as special cases, and we show that similar techniques can be used to significantly simplify the corresponding pricing problems.},
	number = {2},
	urldate = {2016-01-03},
	journal = {Operations Research},
	author = {Gallego, Guillermo and Wang, Ruxian},
	month = mar,
	year = {2014},
	pages = {450--461},
	file = {Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/3U2BPSF2/Gallego and Wang - 2014 - Multiproduct Price Optimization and Competition Un.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/4MIAQ7EW/opre.2013.html:text/html}
}

@article{kohli_representation_2007,
	title = {Representation and {Inference} of {Lexicographic} {Preference} {Models} and {Their} {Variants}},
	volume = {26},
	issn = {0732-2399},
	url = {http://pubsonline.informs.org/doi/abs/10.1287/mksc.1060.0241},
	doi = {10.1287/mksc.1060.0241},
	abstract = {The authors propose two variants of lexicographic preference rules. They obtain the necessary and sufficient conditions under which a linear utility function represents a standard lexicographic rule, and each of the proposed variants, over a set of discrete attributes. They then: (i) characterize the measurement properties of the parameters in the representations; (ii) propose a nonmetric procedure for inferring each lexicographic rule from pairwise comparisons of multiattribute alternatives; (iii) describe a method for distinguishing among different lexicographic rules, and between lexicographic and linear preference models; and (iv) suggest how individual lexicographic rules can be combined to describe hierarchical market structures. The authors illustrate each of these aspects using data on personal-computer preferences. They find that two-thirds of the subjects in the sample use some kind of lexicographic rule. In contrast, only one in five subjects use a standard lexicographic rule. This suggests that lexicographic rules are more widely used by consumers than one might have thought in the absence of the lexicographic variants described in the paper. The authors report a simulation assessing the ability of the proposed inference procedure to distinguish among alternative lexicographic models, and between linear-compensatory and lexicographic models.},
	number = {3},
	urldate = {2016-01-03},
	journal = {Marketing Science},
	author = {Kohli, Rajeev and Jedidi, Kamel},
	month = may,
	year = {2007},
	pages = {380--399},
	file = {Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/KFDPSB73/Kohli and Jedidi - 2007 - Representation and Inference of Lexicographic Pref.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/WS3GMJAT/mksc.1060.html:text/html}
}

@article{cascetta_dominance_2009,
	title = {Dominance among alternatives in random utility models},
	volume = {43},
	issn = {0965-8564},
	url = {http://www.sciencedirect.com/science/article/pii/S0965856408001894},
	doi = {10.1016/j.tra.2008.10.003},
	abstract = {In many discrete choice contexts the actual choice set, including the alternatives effectively perceived and considered by the decision maker, may substantially differ from the universal choice set, including all available alternatives: one of the most relevant examples within transport demand simulation is probably the choice of destination, wherein the universal choice set normally includes hundreds of traffic zones. In these cases, proper simulation of the choice set is crucial for correct simulation of the choice context.

In this regard, our paper has two main objectives. The first is to give a general contribution to choice set modelling by extending and applying the concept of dominance among alternatives to the framework of random utility theory. The main result is the definition of a methodology for the generation of new dominance attributes, which can be used in choice set modelling. The second aim is to make a specific contribution to destination choice modelling: dominance attributes are defined from the above methodology and introduced into this choice context, and new spatial variables reproducing better knowledge of zones with a privileged spatial position are also proposed. Methodology and attributes are tested both on synthetic and on real data.},
	number = {2},
	urldate = {2016-01-03},
	journal = {Transportation Research Part A: Policy and Practice},
	author = {Cascetta, Ennio and Papola, Andrea},
	month = feb,
	year = {2009},
	keywords = {Choice set modelling, Destination choice, dominance},
	pages = {170--179},
	file = {ScienceDirect Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/AB9H5RCH/Cascetta and Papola - 2009 - Dominance among alternatives in random utility mod.pdf:application/pdf;ScienceDirect Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/FZG5CTSU/S0965856408001894.html:text/html}
}

@article{stuttgen_satisficing_2012,
	title = {A {Satisficing} {Choice} {Model}},
	volume = {31},
	issn = {0732-2399},
	url = {http://pubsonline.informs.org/doi/abs/10.1287/mksc.1120.0732},
	doi = {10.1287/mksc.1120.0732},
	abstract = {Although the assumption of utility-maximizing consumers has been challenged for decades, empirical applications of alternative choice rules are still very new. We add to this growing body of literature by proposing a model based on the idea of a {\textquotedblleft}satisficing{\textquotedblright} decision maker. In contrast to previous models (including recent models implementing alternative choice rules), satisficing depends on the order in which alternatives are evaluated. We therefore conduct a visual conjoint experiment to collect search and choice data. We model search and product evaluation jointly and allow for interdependence between them. The choice rule incorporates a conjunctive rule for the evaluations and, contrary to most previous models, does not rely on compensatory trade-offs at all. The results strongly support the proposed model. For instance, we find that search is indeed influenced by product evaluations. More importantly, the model results strongly support the satisficing stopping rule. Finally, we perform a holdout prediction task and find that the proposed model outperforms a standard multinomial logit model.},
	number = {6},
	urldate = {2016-01-03},
	journal = {Marketing Science},
	author = {St{\"u}ttgen, Peter and Boatwright, Peter and Monroe, Robert T.},
	month = sep,
	year = {2012},
	pages = {878--899},
	file = {Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/5M3CJQIB/St{\"u}ttgen et al. - 2012 - A Satisficing Choice Model.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/9Q2GK4KT/mksc.1120.html:text/html}
}

@article{jedidi_probabilistic_2005,
	title = {Probabilistic {Subset}-{Conjunctive} {Models} for {Heterogeneous} {Consumers}},
	volume = {42},
	issn = {0022-2437},
	url = {http://journals.ama.org/doi/abs/10.1509/jmkr.2005.42.4.483},
	doi = {10.1509/jmkr.2005.42.4.483},
	abstract = {The authors propose two generalizations of conjunctive and disjunctive screening rules. First, they relax the requirement that an acceptable alternative must be satisfactory on one criterion (disjunctive) or on all criteria (conjunctive). Second, they relax the assumption that consumers make deterministic judgments when evaluating alternatives. They combine the two generalizations into a probabilistic subset-conjunctive rule, which allows consumers to use any number or subset of decision criteria when screening alternatives and permits them to be uncertain about the acceptability of attribute levels. These two features allow for a screening process that is uncertain and more flexible than the deterministic conjunctive and disjunctive rules currently described in the literature. The authors describe a latent-class method for the estimation of the subset-conjunctive rules and the attribute-level consideration probabilities using either consideration or choice data. Applications using both types of data suggest that the proposed models predict as well as linear models do; can make different predictions of consideration, choice, and market shares; and provide insights into consumer decision processes that are different from those obtained with linear models.},
	number = {4},
	urldate = {2016-01-03},
	journal = {Journal of Marketing Research},
	author = {Jedidi, Kamel and Kohli, Rajeev},
	month = nov,
	year = {2005},
	pages = {483--494},
	file = {jedidi_kohli.pdf:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/QWVEIFH8/jedidi_kohli.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/UCPISN59/jmkr.2005.42.4.html:text/html}
}

@article{gilbride_estimating_2006,
	title = {Estimating {Heterogeneous} {EBA} and {Economic} {Screening} {Rule} {Choice} {Models}},
	volume = {25},
	issn = {0732-2399},
	url = {http://www.jstor.org/stable/40057038},
	abstract = {Consumer choice in surveys and in the marketplace reflects a complex process of screening and evaluating choice alternatives. Behavioral and economic models of choice processes are difficult to estimate when using stated and revealed preferences because the underlying process is latent. This paper introduces Bayesian methods for estimating two behavioral models that eliminate alternatives using specific attribute levels. The elimination by aspects theory postulates a sequential elimination of alternatives by attribute levels until a single one, the chosen alternative, remains. In the economic screening rule model, respondents screen out alternatives with certain attribute levels and then choose from the remaining alternatives, using a compensatory function of all the attributes. The economic screening rule model gives an economic justification as to why certain attributes are used to screen alternatives. A commercial conjoint study is used to illustrate the methods and assess their performance. In this data set, the economic screening rule model outperforms the EBA and other standard choice models and provides comparable results to an equivalent conjunctive screening rule model.},
	number = {5},
	urldate = {2016-01-03},
	journal = {Marketing Science},
	author = {Gilbride, Timothy J. and Allenby, Greg M.},
	year = {2006},
	pages = {494--509},
	file = {JSTOR Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/DMSZFM75/Gilbride and Allenby - 2006 - Estimating Heterogeneous EBA and Economic Screenin.pdf:application/pdf}
}

@article{gilbride_choice_2004,
	title = {A {Choice} {Model} with {Conjunctive}, {Disjunctive}, and {Compensatory} {Screening} {Rules}},
	volume = {23},
	issn = {0732-2399},
	url = {http://www.jstor.org/stable/30036705},
	abstract = {Many theories of consumer behavior involve thresholds and discontinuities. In this paper, we investigate consumers' use of screening rules as part of a discrete-choice model. Alternatives that pass the screen are evaluated in a manner consistent with random utility theory; alternatives that do not pass the screen have a zero probability of being chosen. The proposed model accommodates conjunctive, disjunctive, and compensatory screening rules. We estimate a model that reflects a discontinuous decision process by employing the Bayesian technique of data augmentation and using Markov-chain Monte Carlo methods to integrate over the parameter space. The approach has minimal information requirements and can handle a large number of choice alternatives. The method is illustrated using a conjoint study of cameras. The results indicate that 92\% of respondents screen alternatives on one or more attributes.},
	number = {3},
	urldate = {2016-01-03},
	journal = {Marketing Science},
	author = {Gilbride, Timothy J. and Allenby, Greg M.},
	year = {2004},
	pages = {391--406},
	file = {JSTOR Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/5MWT4DNM/Gilbride and Allenby - 2004 - A Choice Model with Conjunctive, Disjunctive, and .pdf:application/pdf}
}

@article{elrod_new_2004,
	title = {A new integrated model of noncompensatory and compensatory decision strategies},
	volume = {95},
	issn = {0749-5978},
	url = {http://www.sciencedirect.com/science/article/pii/S0749597804000573},
	doi = {10.1016/j.obhdp.2004.06.002},
	abstract = {We describe and test a model that captures conjunctive, disjunctive, and compensatory judgment and choice strategies, as well as selected hybrid combinations of these. This model: (a) can be estimated solely from nonexperimental outcome data, (b) remains true to the conceptualization of noncompensatory heuristics as cognitively less demanding for decision makers, (c) is truly noncompensatory and not just approximately, (d) tests for a {\textquotedblleft}pervasive{\textquotedblright} influence of cutoffs, (e) allows for the possibility that decision makers use different strategies across attributes, and (f) provides a more plausible account of behavior than competing models. We show empirically that decision makers may sometimes devalue objects for almost failing a conjunctive criterion or value objects more favorably for almost passing a disjunctive criterion{\textemdash}what we term a pervasive influence of a cutoff. The superiority of the proposed model relative to two other state-of-the-art models is demonstrated using both actual admit/reject decisions of an MBA admissions office as well as 10 simulations of various decision tasks.},
	number = {1},
	urldate = {2016-01-03},
	journal = {Organizational Behavior and Human Decision Processes},
	author = {Elrod, Terry and Johnson, Richard D. and White, Joan},
	month = sep,
	year = {2004},
	keywords = {Additive models, Choice behavior, Compensatory evaluation, Multiattribute decision making, Noncompensatory evaluation},
	pages = {1--19},
	file = {ScienceDirect Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/FHWUM2BM/Elrod et al. - 2004 - A new integrated model of noncompensatory and comp.pdf:application/pdf;ScienceDirect Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/MTG9QV6E/Elrod et al. - 2004 - A new integrated model of noncompensatory and comp.pdf:application/pdf;ScienceDirect Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/M5DXRMX5/S0749597804000573.html:text/html;ScienceDirect Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/2PPCGN8K/S0749597804000573.html:text/html}
}

@article{komori_asymmetric_2015,
	title = {An asymmetric logistic regression model for ecological data},
	copyright = {{\textcopyright} 2015 The Authors. Methods in Ecology and Evolution published by John Wiley \& Sons Ltd on behalf of British Ecological Society., This is an open access article under the terms of the Creative Commons Attribution-NonCommercial-NoDerivs License, which permits use and distribution in any medium, provided the original work is properly cited, the use is non-commercial and no modifications or adaptations are made.},
	issn = {2041-210X},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/2041-210X.12473/abstract},
	doi = {10.1111/2041-210X.12473},
	abstract = {* Binary data are popular in ecological and environmental studies; however, due to various uncertainties and complexities present in data sets, the standard generalized linear model with a binomial error distribution often demonstrates insufficient predictive performance when analysing binary and proportional data.


* To address this difficulty, we propose an asymmetric logistic regression model that uses a new parameter to account for data complexity. We observe that this parameter controls the model's asymmetry and is important for adjusting the weights associated with observed data in order to improve model fitting. This model includes the ordinary logistic regression model as a special case. It is easily implemented using a slight modification of glm or glmer in statistical software R.


* Simulation studies suggest that our new approach outperforms a traditional approach in terms of both predictive accuracy and variable selection. In a case study involving fisheries data, we found that the annual catch amount had a greater impact on stock status prediction, and improved predictive capability was supported with a smaller AIC compared to a generalized linear model.


* In summary, our method can enhance the applicability of a generalized linear model to various ecological problems using a slight modification, and significantly improves model fitting and model selection.},
	language = {en},
	urldate = {2016-01-03},
	journal = {Methods in Ecology and Evolution},
	author = {Komori, Osamu and Eguchi, Shinto and Ikeda, Shiro and Okamura, Hiroshi and Ichinokawa, Momoko and Nakayama, Shinichiro},
	month = oct,
	year = {2015},
	keywords = {ecological binary data, mixed effect logistic regression, model fitting, Variable selection},
	pages = {n/a--n/a},
	file = {Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/66PEH9PM/Komori et al. - 2015 - An asymmetric logistic regression model for ecolog.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/FWWIFHHJ/abstract.html:text/html}
}

@article{kim_flexible_2008,
	title = {Flexible generalized t-link models for binary response data},
	volume = {95},
	issn = {0006-3444, 1464-3510},
	url = {http://biomet.oxfordjournals.org/content/95/1/93},
	doi = {10.1093/biomet/asm079},
	abstract = {A critical issue in modelling binary response data is the choice of the links. We introduce a new link based on the generalized t-distribution. There are two parameters in the generalized t-link: one parameter purely controls the heaviness of the tails of the link and the second parameter controls the scale of the link. Two major advantages are offered by the generalized t-links. First, a symmetric generalized t-link with an unknown shape parameter is much more identifiable than a Student t-link with unknown degrees of freedom and a known scale parameter. Secondly, skewed generalized t-links with both unknown shape and scale parameters provide much more flexible and improved skewed link regression models than the existing skewed links. Various theoretical properties and attractive features of the proposed links are examined and explored in detail. An efficient Markov chain Monte Carlo algorithm is developed for sampling from the posterior distribution. The deviance information criterion measure is used for guiding the choice of links. The proposed methodology is motivated and illustrated by prostate cancer data.},
	language = {en},
	number = {1},
	urldate = {2016-01-03},
	journal = {Biometrika},
	author = {Kim, Sungduk and Chen, Ming-Hui and Dey, Dipak K.},
	month = mar,
	year = {2008},
	keywords = {Latent variable; Logistic regression, Markov Chain Monte Carlo, Mixed-effects model, posterior distribution, Probit link, Robit link.},
	pages = {93--106},
	file = {Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/ZSMZM2C2/Kim et al. - 2008 - Flexible generalized t-link models for binary resp.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/ZDU29XA7/93.html:text/html}
}

@article{sahu_new_2003,
	title = {A new class of multivariate skew distributions with applications to bayesian regression models},
	volume = {31},
	copyright = {Copyright {\textcopyright} 2003 Statistical Society of Canada},
	issn = {1708-945X},
	url = {http://onlinelibrary.wiley.com/doi/10.2307/3316064/abstract},
	doi = {10.2307/3316064},
	abstract = {Abstract: The authors develop a new class of distributions by introducing skewness in multivariate elliptically symmetric distributions. The class, which is obtained by using transformation and conditioning, contains many standard families including the multivariate skew-normal and t distributions. The authors obtain analytical forms of the densities and study distributional properties. They give practical applications in Bayesian regression models and results on the existence of the posterior distributions and moments under improper priors for the regression coefficients. They illustrate their methods using practical examples.},
	language = {en},
	number = {2},
	urldate = {2016-01-03},
	journal = {Canadian Journal of Statistics},
	author = {Sahu, Sujit K. and Dey, Dipak K. and Branco, M{\'a}rcia D.},
	month = jun,
	year = {2003},
	keywords = {elliptical distributions, Gibbs sampler, heavy tailed error distribution, Key words and phrases: Bayesian inference, Markov Chain Monte Carlo, multivariate skewness.},
	pages = {129--150},
	file = {Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/NJCVINP2/Sahu et al. - 2003 - A new class of multivariate skew distributions wit.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/NHVCER7K/abstract.html:text/html}
}

@techreport{san_francisco_metropolitan_transportation_commission_travel_2012,
	title = {Travel {Model} {Development}: {Calibration} and {Validation}},
	url = {http://mtcgis.mtc.ca.gov/foswiki/pub/Main/Documents/2012_05_18_RELEASE_DRAFT_Calibration_and_Validation.pdf},
	urldate = {2016-01-03},
	institution = {San Francisco Metropolitan Transportaton Commission},
	author = {San Francisco Metropolitan Transportation Commission and Parsons Brinckerhoff},
	month = may,
	year = {2012},
	pages = {213},
	file = {2012_05_18_RELEASE_DRAFT_Calibration_and_Validation.pdf:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/AKC7V33T/2012_05_18_RELEASE_DRAFT_Calibration_and_Validation.pdf:application/pdf}
}

@article{swait_non-compensatory_2001,
	title = {A non-compensatory choice model incorporating attribute cutoffs},
	volume = {35},
	issn = {0191-2615},
	url = {http://www.sciencedirect.com/science/article/pii/S0191261500000308},
	doi = {10.1016/S0191-2615(00)00030-8},
	abstract = {This research proposes an extension to the traditional compensatory utility maximization framework which has guided most theoretical and statistical work in choice modeling applications, including those in transportation demand estimation work. Attribute cutoffs are incorporated into the decision problem formulation; it is then argued on extant empirical evidence that individuals may view these constraints as {\textquotedblleft}soft{\textquotedblright}. This leads to the formulation of a penalized utility function that allows for constraint violation, but at a cost to the overall evaluation of the good. The proposed model is able to represent fully compensatory, conjunctive and disjunctive choice strategies, as well as combinations thereof. The properties of the proposed theoretical model are examined and discussed. From the theoretical framework, statistical models of choice behavior are easily derived; in their simplest forms, these models can be estimated using existing software. A Stated Preference choice experiment is analyzed using the proposed model, which is found to be highly consistent with observed choices and superior to a structural two-stage choice set formation model.},
	number = {10},
	urldate = {2016-01-04},
	journal = {Transportation Research Part B: Methodological},
	author = {Swait, Joffre},
	month = nov,
	year = {2001},
	keywords = {Heuristic decision-making, Non-compensatory choice, SP data},
	pages = {903--928},
	file = {ScienceDirect Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/AG7CJZ5H/Swait - 2001 - A non-compensatory choice model incorporating attr.pdf:application/pdf;ScienceDirect Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/KEQKXJ4Z/S0191261500000308.html:text/html}
}

@incollection{winkler_scoring_2010,
	title = {Scoring {Rules}},
	copyright = {Copyright {\textcopyright} 2010 John Wiley \& Sons, Inc. All rights reserved.},
	isbn = {978-0-470-40053-1},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/9780470400531.eorms0749/abstract},
	abstract = {Probabilities are used to quantify uncertainty in operations research and management science modeling. Scoring rules provide a numerical measure (a score or reward) based on probabilities for an event or variable and on what actually occurs. As such, they are valuable in evaluating how {\textquotedblleft}good{\textquotedblright} probabilities are in light of what happens, and they also provide incentives for careful elicitation of probabilities. We discuss basic properties of scoring rules, present families of scoring rules that are useful under various conditions, and discuss some related issues.},
	language = {en},
	urldate = {2016-01-04},
	booktitle = {Wiley {Encyclopedia} of {Operations} {Research} and {Management} {Science}},
	publisher = {John Wiley \& Sons, Inc.},
	author = {Winkler, Robert L. and Jose, Victor Richmond R. and Cochran, James J. and Cox, Louis A. and Keskinocak, Pinar and Kharoufeh, Jeffrey P. and Smith, J. Cole},
	year = {2010},
	keywords = {baseline distributions, Calibration, decision analysis, probability elicitation, probability evaluation, sensitivity to distance, sharpness, strictly proper scoring rules},
	file = {Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/EJZ6K3FC/Winkler et al. - 2010 - Scoring Rules.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/BB66CXIA/abstract.html:text/html}
}

@techreport{california_department_of_transportation_california_2002,
	title = {{CALIFORNIA} {BLUEPRINT} {FOR} {BICYCLING} {AND} {WALKING} : {REPORT} {TO} {THE} {LEGISLATURE}},
	shorttitle = {{CALIFORNIA} {BLUEPRINT} {FOR} {BICYCLING} {AND} {WALKING}},
	url = {http://www.dot.ca.gov/hq/LocalPrograms/bike/CABlueprintRpt.pdf},
	urldate = {2016-01-19},
	institution = {California Department of Transportation},
	author = {{California Department of Transportation}},
	year = {2002},
	file = {Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/MJHWU45G/view.html:text/html}
}

@phdthesis{japkowicz_concept-learning_1999,
	title = {Concept-learning in the absence of counter-examples: an autoassociation-based approach to classification},
	shorttitle = {Concept-learning in the absence of counter-examples},
	url = {http://www.researchgate.net/profile/Stephen_Hanson3/publication/2293736_Concept-Learning_In_The_Absence_Of_Counter-Examples_An_Autoassociation-Based_Approach_To_Classification/links/02e7e51b889e587d59000000.pdf},
	urldate = {2016-01-19},
	school = {Rutgers, The State University of New Jersey},
	author = {Japkowicz, Nathalie},
	year = {1999},
	file = {[PDF] from researchgate.net:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/VATC7CEK/Japkowicz - 1999 - Concept-learning in the absence of counter-example.pdf:application/pdf}
}

@article{swait_empirical_1987,
	title = {Empirical test of a constrained choice discrete model: {Mode} choice in {S{\~a}o} {Paulo}, {Brazil}},
	volume = {21},
	issn = {0191-2615},
	shorttitle = {Empirical test of a constrained choice discrete model},
	url = {http://www.sciencedirect.com/science/article/pii/0191261587900105},
	doi = {10.1016/0191-2615(87)90010-5},
	abstract = {This paper examines the properties and empirically tests a model of discrete choice which incorporates probabilistic choice set generation. Denominated the Parametrized Logit Captivity (PLC) model, it is a generalization of the well-known {\textquotedblleft}dogit{\textquotedblright} specification. The PLC model is shown to be theoretically and empirically more flexible than the latter. Work mode choice data collected in a 1977 O/D survey in S{\~a}o Paulo, Brazil, is used to obtain parameter estimates, as well as to evaluate consumer reaction to a series of perturbations in travel time, travel cost and income, for both the PLC and Multinomial Logit models. Comparisons between the two specifications are made in terms of statistical fit, reasonableness of predictions and differences in predictions across models.},
	number = {2},
	urldate = {2016-01-19},
	journal = {Transportation Research Part B: Methodological},
	author = {Swait, Joffre and Ben-Akiva, Moshe},
	month = apr,
	year = {1987},
	pages = {103--115},
	file = {1-s2.0-0191261587900105-main.pdf:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/7BQIKCUN/1-s2.0-0191261587900105-main.pdf:application/pdf;ScienceDirect Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/2SBQ47MP/0191261587900105.html:text/html;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/SIBWHH5W/0191261587900105.html:text/html}
}

@article{swait_choice_2009,
	title = {Choice models based on mixed discrete/continuous {PDFs}},
	volume = {43},
	issn = {0191-2615},
	url = {http://www.sciencedirect.com/science/article/pii/S0191261509000216},
	doi = {10.1016/j.trb.2009.02.003},
	abstract = {This paper introduces a variant of random utility choice models based on mixed probability density functions, hence the adopted moniker {\textquotedblleft}k-Mix models.{\textquotedblright} Mixed pdf{\textquoteright}s contain components with the usual continuous density function specifications that underlie common choice models (e.g. MNL, GEV, MNP), but also contain one or more discrete probability mass points. These mixed pdf{\textquoteright}s result in models that can be interpreted to reflect different regimes of decision-making. Two exemplars developed in this paper, the 2- and 3-Mix models, are the result of a mixed pdf that combines a continuous pdf, plus one or two mass points, respectively. The 2-Mix permits a specific alternative to be in the Tradeoff Condition (the usual situation for alternatives in extant choice models, and the only regime in which compensatory utility is defined and compared) or in the Rejection Condition (in which an alternative has extreme disutility). The 3-Mix model adds the Dominance Condition (in which an alternative has an extremely attractive utility) {\textendash} interestingly, the inclusion of this condition makes the model capable of simulating a particular form of satisficing decision making. These models are derived, discussed and compared relative to several extant choice models, then applied empirically on both a RP data set (work trip mode choice) and a SP data set (recreation campsite selection).},
	number = {7},
	urldate = {2016-01-19},
	journal = {Transportation Research Part B: Methodological},
	author = {Swait, Joffre},
	month = aug,
	year = {2009},
	keywords = {Choice model, decision rules, Mixed PDF, Non-compensatory behavior, Random utility},
	pages = {766--783},
	file = {ScienceDirect Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/MK3FHM6S/Swait - 2009 - Choice models based on mixed discretecontinuous P.pdf:application/pdf;ScienceDirect Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/CSDRCC3I/S0191261509000216.html:text/html}
}

@article{li_effect_2015,
	title = {The effect of choice set misspecification on welfare measures in random utility models},
	volume = {42},
	issn = {0928-7655},
	url = {http://www.sciencedirect.com/science/article/pii/S0928765515000512},
	doi = {10.1016/j.reseneeco.2015.07.001},
	abstract = {Random utility models have been widely employed in environmental valuation. But stochastic choice set formation models in the random utility framework are rarely applied in this literature, although previous research has shown that ignoring choice set formation (when it exists) leads to biased parameter estimates and welfare measures. This paper conducts Monte Carlo (MC) experiments to investigate the directionality and magnitude of welfare measure bias arising from ignoring or misspecifying choice set formation. We find that when attribute cutoff-based choice set formation exists in the data generation process, typical RUM models ignoring or misspecifying choice set formation underestimate welfare measures by 30{\textendash}50\%. Models that approximate choice set formation may produce unbiased welfare measures, but constitute a promising area for future research. This paper illustrates the importance of applying choice set formation in environmental valuation and provides practical guidance about the usage of stochastic choice set formation models.},
	urldate = {2016-01-19},
	journal = {Resource and Energy Economics},
	author = {Li, Lianhua and Adamowicz, Wiktor and Swait, Joffre},
	month = nov,
	year = {2015},
	keywords = {Choice model, Choice set formation, Random utility, Welfare measures},
	pages = {71--92},
	file = {ScienceDirect Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/UHA2TC4T/Li et al. - 2015 - The effect of choice set misspecification on welfa.pdf:application/pdf;ScienceDirect Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/CNS9R57A/S0928765515000512.html:text/html}
}

@inproceedings{mahmoud_latent_2015,
	title = {Latent {Captivation} or {Mode} {Culture}? {Investigation} into {Mode} {Choice} {Preference} {Structures} in {Competitive} {Modal} {Arrangements}},
	shorttitle = {Latent {Captivation} or {Mode} {Culture}?},
	url = {http://trid.trb.org/view.aspx?id=1337392},
	urldate = {2016-01-20},
	author = {Mahmoud, Mohamed Salah and Weiss, Adam and Habib, Khandker Nurul},
	year = {2015},
	file = {Mahmoud et al. 2015.pdf:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/QFATE3B7/Mahmoud et al. 2015.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/TIGI5E4V/view.html:text/html}
}

@techreport{chen_using_2004,
	title = {Using random forest to learn imbalanced data},
	url = {http://statistics.berkeley.edu/sites/default/files/tech-reports/666.pdf},
	institution = {University of California, Berkeley},
	author = {Chen, Chao and Liaw, Andy and Breiman, Leo},
	year = {2004},
	file = {666.pdf:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/BZDMDRVU/666.pdf:application/pdf}
}

@techreport{cleland_why_2004,
	address = {New Zealand},
	title = {Why don{\textquoteright}t people walk and cycle},
	url = {http://can.org.nz/system/files/Why%20dont%20people%20walk%20and%20cycle.pdf},
	number = {528007},
	urldate = {2016-01-20},
	institution = {Central Laboratories},
	author = {Cleland, B. S. and Walton, D.},
	month = jul,
	year = {2004},
	file = {[PDF] from can.org.nz:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/AFVWRIN4/Cleland and Walton - 2004 - Why don{\textquoteright}t people walk and cycle.pdf:application/pdf}
}

@book{goldsmith_reasons_1992,
	title = {Reasons why bicycling and walking are and are not being used more extensively as travel modes},
	url = {http://safety.fhwa.dot.gov/ped_bike/docs/case1.pdf},
	number = {1},
	publisher = {Federal Highway Administration},
	author = {Goldsmith, Stewart A.},
	year = {1992},
	file = {case1.pdf:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/ITBCDN8X/case1.pdf:application/pdf}
}

@techreport{u.s._census_bureau_b08006:_2014,
	title = {B08006: {Sex} of {Workers} by {Means} of {Transportation} to {Work}},
	url = {http://factfinder.census.gov/faces/tableservices/jsf/pages/productview.xhtml?pid=ACS_14_5YR_B08006&prodType=table},
	author = {{U.S. Census Bureau}},
	year = {2014}
}

@article{becker_irrational_1962,
    title = {Irrational {Behavior} and {Economic} {Theory}},
    volume = {70},
    issn = {0022-3808},
    url = {http://www.jstor.org/stable/1827018},
    number = {1},
    urldate = {2016-01-24},
    journal = {Journal of Political Economy},
    author = {Becker, Gary S.},
    year = {1962},
    pages = {1--13},
    file = {JSTOR Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/B4JZKR5H/Becker - 1962 - Irrational Behavior and Economic Theory.pdf:application/pdf}
}

@article{calabrese_modelling_2013,
	title = {Modelling small and medium enterprise loan defaults as rare events: the generalized extreme value regression model},
	volume = {40},
	issn = {0266-4763},
	shorttitle = {Modelling small and medium enterprise loan defaults as rare events},
	url = {http://dx.doi.org/10.1080/02664763.2013.784894},
	doi = {10.1080/02664763.2013.784894},
	abstract = {A pivotal characteristic of credit defaults that is ignored by most credit scoring models is the rarity of the event. The most widely used model to estimate the probability of default is the logistic regression model. Since the dependent variable represents a rare event, the logistic regression model shows relevant drawbacks, for example, underestimation of the default probability, which could be very risky for banks. In order to overcome these drawbacks, we propose the generalized extreme value regression model. In particular, in a generalized linear model (GLM) with the binary-dependent variable we suggest the quantile function of the GEV distribution as link function, so our attention is focused on the tail of the response curve for values close to one. The estimation procedure used is the maximum-likelihood method. This model accommodates skewness and it presents a generalisation of GLMs with complementary log{\textendash}log link function. We analyse its performance by simulation studies. Finally, we apply the proposed model to empirical data on Italian small and medium enterprises.},
	number = {6},
	urldate = {2014-08-31},
	journal = {Journal of Applied Statistics},
	author = {Calabrese, Raffaella and Osmetti, Silvia Angela},
	month = apr,
	year = {2013},
	pages = {1172--1188},
	file = {Modelling small and medium enterprise loan defaults as rare events--the generalized extreme value regression model.pdf:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/H89HFX3A/Modelling small and medium enterprise loan defaults as rare events--the generalized extreme value regression model.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/AEPXW82U/02664763.2013.html:text/html}
}

@article{bazan_framework_2010,
	title = {A {Framework} for {Skew}-{Probit} {Links} in {Binary} {Regression}},
	volume = {39},
	issn = {0361-0926},
	url = {http://dx.doi.org/10.1080/03610920902783849},
	doi = {10.1080/03610920902783849},
	abstract = {We review several asymmetrical links for binary regression models and present a unified approach for two skew-probit links proposed in the literature. Moreover, under skew-probit link, conditions for the existence of the ML estimators and the posterior distribution under improper priors are established. The framework proposed here considers two sets of latent variables which are helpful to implement the Bayesian MCMC approach. A simulation study to criteria for models comparison is conducted and two applications are made. Using different Bayesian criteria we show that, for these data sets, the skew-probit links are better than alternative links proposed in the literature.},
	number = {4},
	urldate = {2015-03-01},
	journal = {Communications in Statistics - Theory and Methods},
	author = {Baz{\'a}n, Jorge L. and Bolfarine, Heleno and Branco, M{\'a}rcia D.},
	month = feb,
	year = {2010},
	pages = {678--697},
	file = {Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/PMNU3GWE/Baz{\'a}n et al. - 2010 - A Framework for Skew-Probit Links in Binary Regres.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/7VB8UPBS/03610920902783849.html:text/html}
}

@article{yates_use_1955,
	title = {The {Use} of {Transformations} and {Maximum} {Likelihood} in the {Analysis} of {Quantal} {Experiments} {Involving} {Two} {Treatments}},
	volume = {42},
	issn = {0006-3444},
	url = {http://www.jstor.org/stable/2333385},
	doi = {10.2307/2333385},
	number = {3/4},
	urldate = {2016-03-25},
	journal = {Biometrika},
	author = {Yates, Frank},
	year = {1955},
	pages = {382--403},
	file = {2333385.pdf:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/9ZZUVIFU/2333385.pdf:application/pdf}
}

@incollection{horowitz_semiparametric_1993,
	series = {Handbook of Statistics},
	title = {Semiparametric and nonparametric estimation of quantal response models},
	volume = {11},
	url = {http://www.sciencedirect.com/science/article/pii/S0169716105800379},
	abstract = {This chapter presents some of the results on semi- and nonparametric estimation of quantal response models. It concentrates on methods for binary response models{\textemdash}that is, models in which the dependent variable has only two states, such as employed or unemployed. Semi- and nonparametric methods for binary response models are more highly developed than are such methods for models with multiple responses, and to date binary response is the only setting in which semi- or nonparametric methods have been applied. The chapter reviews parametric models, identifies the assumptions of these models that semi- and nonparametric methods relax, and explains the distinction between semi- and nonparametric methods. The consequences of adopting a misspecified parametric model are discussed as they are important because semi- and nonparametric methods are not needed if the errors resulting from use of a misspecified parametric model are small. The chapter discusses the problem of identifying behavioral parameters when parametric assumptions are relaxed, the rates of convergence and asymptotic efficiency in semiparametric models, the methods for semi- and nonparametric estimation of binary response models, the estimation from choice-based samples, the few applications of semiparametric estimators for binary response models, and models for multinomial responses.},
	urldate = {2016-03-25},
	publisher = {Elsevier},
	author = {Horowitz, Joel L.},
	editor = {Statistics, BT  - Handbook of},
	year = {1993},
	pages = {45--72},
	file = {ScienceDirect Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/T782Z7J4/Horowitz - 1993 - 2 Semiparametric and nonparametric estimation of q.pdf:application/pdf;ScienceDirect Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/IBMWFMP3/S0169716105800379.html:text/html}
}


@article{hausman_conditional_1978,
	title = {A {Conditional} {Probit} {Model} for {Qualitative} {Choice}: {Discrete} {Decisions} {Recognizing} {Interdependence} and {Heterogeneous} {Preferences}},
	volume = {46},
	issn = {0012-9682},
	shorttitle = {A {Conditional} {Probit} {Model} for {Qualitative} {Choice}},
	url = {http://www.jstor.org/stable/1913909},
	doi = {10.2307/1913909},
	abstract = {To date, the most widely used method for empirical analysis of multiple alternative qualitative choices has been an extension of binary logit analysis called conditional logit analysis. Although this method is extremely attractive because of its computational simplicity, it is burdened with a property termed the "independence of irrelevant alternatives" that is quite unrealistic in many choice situations. We have proposed in this paper a computationally feasible method of estimation not constrained by the independence restriction and which allows for a much richer range of human behavior than does the conditional logit model. An important characteristic of the model is provision for correlation among the random components of utility and, as a by-product, the explicit allowance for variation in tastes across individuals for the attributes of alternatives. We have demonstrated the model and compared it with the logit one by analyzing the travel mode choice decisions of commuters to the central business district of Washington, D.C. Substantial differences are found in predictions based on the two models. The example allows three alternatives. Extension to four or five is quite feasible.},
	number = {2},
	urldate = {2016-03-30},
	journal = {Econometrica},
	author = {Hausman, Jerry A. and Wise, David A.},
	year = {1978},
	pages = {403--426},
	file = {1913909.pdf:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/S9SU6JA5/1913909.pdf:application/pdf}
}

@book{bell_transportation_1997,
	title = {{TRANSPORTATION} {NETWORK} {ANALYSIS}},
	isbn = {978-0-471-96493-3},
	url = {http://trid.trb.org/view.aspx?id=573501},
	urldate = {2016-03-30},
	author = {Bell, M. G. H. and Iida, Y.},
	year = {1997},
	file = {Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/RVJ7G9GD/view.html:text/html}
}

@article{horowitz_accuracy_1980,
	title = {The accuracy of the multinomial logit model as an approximation to the multinomial probit model of travel demand},
	volume = {14},
	issn = {0191-2615},
	url = {http://www.sciencedirect.com/science/article/pii/0191261580900132},
	doi = {10.1016/0191-2615(80)90013-2},
	abstract = {The multinomial probit model of travel demand is considerably more general but much less tractable than the better-known multinomial logit model. In an effort to determine the effects of using the relatively simple logit model in situations where the assumptions of probit modeling are satisfied but those of logit modeling are not, the accuracy of the multinomial logit model as an approximation to a variety of three-alternative probit models has been evaluated. Multinomial logit can give highly erroneous estimates of the choice probabilities of multinomial probit models. However, logit models appear to give asymptotically accurate estimates of the ratios of the coefficients of the systematic components of probit utility functions, even when the logit choice probabilities differ greatly from the probit ones. Large estimation data sets are not necessarily needed to enable likelihood ratio tests to distinguish three-alternative probit models from logit models that give seriously erroneous estimates of the probit choice probabilities. Inclusion of alternative-specific dummy variables in logit utility functions cannot be relied upon to reduce significantly the errors of logit approximations to the choice probabilities of probit models whose utility functions do not contain the dummies.},
	number = {4},
	urldate = {2016-01-03},
	journal = {Transportation Research Part B: Methodological},
	author = {Horowitz, Joel},
	month = dec,
	year = {1980},
	pages = {331--341},
	file = {1-s2.0-0191261580900132-main.pdf:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/ZPWMW7GW/1-s2.0-0191261580900132-main.pdf:application/pdf;ScienceDirect Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/TX37X8C5/0191261580900132.html:text/html}
}

@article{cortes_support-vector_1995,
	title = {Support-vector networks},
	volume = {20},
	issn = {0885-6125, 1573-0565},
	url = {http://link.springer.com/article/10.1007/BF00994018},
	doi = {10.1007/BF00994018},
	abstract = {Thesupport-vector network is a new learning machine for two-group classification problems. The machine conceptually implements the following idea: input vectors are non-linearly mapped to a very high-dimension feature space. In this feature space a linear decision surface is constructed. Special properties of the decision surface ensures high generalization ability of the learning machine. The idea behind the support-vector network was previously implemented for the restricted case where the training data can be separated without errors. We here extend this result to non-separable training data. High generalization ability of support-vector networks utilizing polynomial input transformations is demonstrated. We also compare the performance of the support-vector network to various classical learning algorithms that all took part in a benchmark study of Optical Character Recognition.},
	language = {en},
	number = {3},
	urldate = {2016-04-06},
	journal = {Machine Learning},
	author = {Cortes, Corinna and Vapnik, Vladimir},
	month = sep,
	year = {1995},
	keywords = {Artificial Intelligence (incl. Robotics), Automation and Robotics, Computing Methodologies, efficient learning algorithms, Language Translation and Linguistics, neural networks, pattern recognition, polynomial classifiers, radial basis function classifiers, Simulation and Modeling},
	pages = {273--297},
	file = {Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/23QWARJG/Cortes and Vapnik - 1995 - Support-vector networks.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/APU4EDGC/bf00994018.html:text/html}
}

@article{lin_note_2004,
	title = {A note on margin-based loss functions in classification},
	volume = {68},
	issn = {0167-7152},
	url = {http://www.sciencedirect.com/science/article/pii/S0167715204000707},
	doi = {10.1016/j.spl.2004.03.002},
	abstract = {In many classification procedures, the classification function is obtained by minimizing a certain empirical risk on the training sample. The classification is then based on the sign of the classification function. In recent years, there have been a host of classification methods proposed that use different margin-based loss functions. The margin-based loss functions are often motivated as upper bounds of the misclassification loss, but this cannot explain the statistical properties of the classification procedures. We show that a large family of margin-based loss functions are Fisher consistent for classification. That is, the population minimizer of the loss function leads to the Bayes optimal rule of classification. Our result covers almost all margin-based loss functions that have been proposed in the literature. We give an inequality that links the Fisher consistency of margin-based loss functions with the consistency of methods based on these loss functions. We use this inequality to obtain the rate of convergence for the method of sieves based on a class of margin-based loss functions.},
	number = {1},
	urldate = {2016-04-06},
	journal = {Statistics \& Probability Letters},
	author = {Lin, Yi},
	month = jun,
	year = {2004},
	keywords = {Bayes rule of classification, Fisher consistency, Margin, Method of regularization, Method of sieves},
	pages = {73--82},
	file = {ScienceDirect Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/SHTCZBKM/Lin - 2004 - A note on margin-based loss functions in classific.pdf:application/pdf;ScienceDirect Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/GZ67S8AT/S0167715204000707.html:text/html}
}

@incollection{rosset_margin_2004,
	title = {Margin {Maximizing} {Loss} {Functions}},
	url = {http://papers.nips.cc/paper/2433-margin-maximizing-loss-functions.pdf},
	urldate = {2016-04-06},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 16},
	publisher = {MIT Press},
	author = {Rosset, Saharon and Zhu, Ji and Hastie, Trevor J.},
	editor = {Thrun, S. and Saul, L. K. and Sch{\"o}lkopf, B.},
	year = {2004},
	pages = {1237--1244},
	file = {NIPS Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/P7RFGAC3/Rosset et al. - 2004 - Margin Maximizing Loss Functions.pdf:application/pdf;NIPS Snapshort:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/ICCTIKXZ/2433-margin-maximizing-loss-functions.html:text/html}
}

@article{xu_sparse_2012,
	title = {Sparse {Algorithms} {Are} {Not} {Stable}: {A} {No}-{Free}-{Lunch} {Theorem}},
	volume = {34},
	issn = {0162-8828},
	shorttitle = {Sparse {Algorithms} {Are} {Not} {Stable}},
	doi = {10.1109/TPAMI.2011.177},
	abstract = {We consider two desired properties of learning algorithms: sparsity and algorithmic stability. Both properties are believed to lead to good generalization ability. We show that these two properties are fundamentally at odds with each other: A sparse algorithm cannot be stable and vice versa. Thus, one has to trade off sparsity and stability in designing a learning algorithm. In particular, our general result implies that l1-regularized regression (Lasso) cannot be stable, while l2-regularized regression is known to have strong stability properties and is therefore not sparse.},
	number = {1},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Xu, H. and Caramanis, C. and Mannor, S.},
	month = jan,
	year = {2012},
	keywords = {Algorithm design and analysis, algorithmic stability, generalization ability, l1-regularized regression, l2-regularized regression, Lasso, learning algorithms, learning (artificial intelligence), Machine learning algorithms, no-free-lunch theorem, Regression analysis, regularization., Signal processing algorithms, sparse algorithms, sparsity, stability, Stability criteria, Support vector machines},
	pages = {187--193},
	file = {IEEE Xplore Abstract Record:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/92WQQZ67/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/S4S22H6C/Xu et al. - 2012 - Sparse Algorithms Are Not Stable A No-Free-Lunch .pdf:application/pdf}
}

@article{tipping_sparse_2001,
	title = {Sparse {Bayesian} {Learning} and the {Relevance} {Vector} {Machine}},
	volume = {1},
	issn = {1532-4435},
	url = {http://dx.doi.org/10.1162/15324430152748236},
	doi = {10.1162/15324430152748236},
	abstract = {This paper introduces a general Bayesian framework for obtaining sparse solutions to regression and classification tasks utilising models linear in the parameters. Although this framework is fully general, we illustrate our approach with a particular specialisation that we denote the 'relevance vector machine' (RVM), a model of identical functional form to the popular and state-of-the-art 'support vector machine' (SVM). We demonstrate that by exploiting a probabilistic Bayesian learning framework, we can derive accurate prediction models which typically utilise dramatically fewer basis functions than a comparable SVM while offering a number of additional advantages. These include the benefits of probabilistic predictions, automatic estimation of 'nuisance' parameters, and the facility to utilise arbitrary basis functions (e.g. non-'Mercer' kernels). We detail the Bayesian framework and associated learning algorithm for the RVM, and give some illustrative examples of its application along with some comparative benchmarks. We offer some explanation for the exceptional degree of sparsity obtained, and discuss and demonstrate some of the advantageous features, and potential extensions, of Bayesian relevance learning.},
	urldate = {2016-04-06},
	journal = {J. Mach. Learn. Res.},
	author = {Tipping, Michael E.},
	month = sep,
	year = {2001},
	pages = {211--244},
	file = {ACM Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/X2FV67VP/Tipping - 2001 - Sparse Bayesian Learning and the Relevance Vector .pdf:application/pdf}
}

@article{bach_optimization_2012,
	title = {Optimization with {Sparsity}-{Inducing} {Penalties}},
	volume = {4},
	issn = {1935-8237},
	url = {http://dx.doi.org/10.1561/2200000015},
	doi = {10.1561/2200000015},
	abstract = {Sparse estimation methods are aimed at using or obtaining parsimonious representations of data or models. They were first dedicated to linear variable selection but numerous extensions have now emerged such as structured sparsity or kernel selection. It turns out that many of the related estimation problems can be cast as convex optimization problems by regularizing the empirical risk with appropriate nonsmooth norms. The goal of this monograph is to present from a general perspective optimization tools and techniques dedicated to such sparsity-inducing penalties. We cover proximal methods, block-coordinate descent, reweighted l2-penalized techniques, working-set and homotopy methods, as well as non-convex formulations and extensions, and provide an extensive set of experiments to compare various algorithms from a computational point of view.},
	number = {1},
	urldate = {2016-04-06},
	journal = {Found. Trends Mach. Learn.},
	author = {Bach, Francis and Jenatton, Rodolphe and Mairal, Julien and Obozinski, Guillaume},
	month = jan,
	year = {2012},
	pages = {1--106}
}

@article{kyung_penalized_2010,
	title = {Penalized regression, standard errors, and {Bayesian} lassos},
	volume = {5},
	issn = {1936-0975, 1931-6690},
	url = {http://projecteuclid.org/euclid.ba/1340218343},
	abstract = {Penalized regression methods for simultaneous variable selection and coefficient estimation, especially those based on the lasso of Tibshirani (1996), have received a great deal of attention in recent years, mostly through frequentist models. Properties such as consistency have been studied, and are achieved by different lasso variations. Here we look at a fully Bayesian formulation of the problem, which is flexible enough to encompass most versions of the lasso that have been previously considered. The advantages of the hierarchical Bayesian formulations are many. In addition to the usual ease-of-interpretation of hierarchical models, the Bayesian formulation produces valid standard errors (which can be problematic for the frequentist lasso), and is based on a geometrically ergodic Markov chain. We compare the performance of the Bayesian lassos to their frequentist counterparts using simulations, data sets that previous lasso papers have used, and a difficult modeling problem for predicting the collapse of governments around the world. In terms of prediction mean squared error, the Bayesian lasso performance is similar to and, in some cases, better than, the frequentist lasso.},
	language = {EN},
	number = {2},
	urldate = {2016-04-06},
	journal = {Bayesian Analysis},
	author = {Kyung, Minjung and Gill, Jeff and Ghosh, Malay and Casella, George},
	month = jun,
	year = {2010},
	mrnumber = {MR2719657},
	keywords = {Geometric Ergodicity, Gibbs sampling, Hierarchical Models, Variable selection},
	pages = {369--411},
	file = {Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/GK5UGSTU/1340218343.html:text/html}
}

@article{liu_hard_2011,
	title = {Hard or {Soft} {Classification}? {Large}-{Margin} {Unified} {Machines}},
	volume = {106},
	issn = {0162-1459},
	shorttitle = {Hard or {Soft} {Classification}?},
	url = {http://dx.doi.org/10.1198/jasa.2011.tm10319},
	doi = {10.1198/jasa.2011.tm10319},
	abstract = {Margin-based classifiers have been popular in both machine learning and statistics for classification problems. Among numerous classifiers, some are hard classifiers while some are soft ones. Soft classifiers explicitly estimate the class conditional probabilities and then perform classification based on estimated probabilities. In contrast, hard classifiers directly target the classification decision boundary without producing the probability estimation. These two types of classifiers are based on different philosophies and each has its own merits. In this article, we propose a novel family of large-margin classifiers, namely large-margin unified machines (LUMs), which covers a broad range of margin-based classifiers including both hard and soft ones. By offering a natural bridge from soft to hard classification, the LUM provides a unified algorithm to fit various classifiers and hence a convenient platform to compare hard and soft classification. Both theoretical consistency and numerical performance of LUMs are explored. Our numerical study sheds some light on the choice between hard and soft classifiers in various classification problems.},
	number = {493},
	urldate = {2016-04-06},
	journal = {Journal of the American Statistical Association},
	author = {Liu, Yufeng and Zhang, Hao Helen and Wu, Yichao},
	month = mar,
	year = {2011},
	pages = {166--177},
	file = {Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/PHPUDQRB/Liu et al. - 2011 - Hard or Soft Classification Large-Margin Unified .pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/GKWA7S2Q/jasa.2011.html:text/html}
}

@article{de_grange_polarized_2013,
	title = {A polarized logit model},
	volume = {53},
	issn = {0965-8564},
	url = {http://www.sciencedirect.com/science/article/pii/S0965856413001122},
	doi = {10.1016/j.tra.2013.06.003},
	abstract = {A novel logit-type discrete choice model is presented whose distinctive characteristic is that it {\textquotedblleft}polarizes{\textquotedblright} or forces the prediction of choice probabilities towards values of 0 or 1. In real-world empirical tests this property enabled the new formulation, which we call the polarized logit model (PLM), to outperform the predictive capacity of other classical discrete choice models. The PLM is derived from the optimality conditions of a maximum entropy optimization model with linear and quadratic constraints. These conditions yield a fixed-point logit probability function that exhibits endogeneity, which is corrected for using instrumental variables so that the model{\textquoteright}s parameters can be estimated. The PLM{\textquoteright}s marginal substitution rates are similar to those of the traditional logit models.},
	urldate = {2016-04-06},
	journal = {Transportation Research Part A: Policy and Practice},
	author = {de Grange, Louis and Gonz{\'a}lez, Felipe and Vargas, Ignacio and Mu{\~n}oz, Juan Carlos},
	month = jul,
	year = {2013},
	keywords = {Endogeneity, Fixed point, Logit model, maximum entropy, prediction, Quadratic constraint},
	pages = {1--9},
	file = {ScienceDirect Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/CVNGUAC9/de Grange et al. - 2013 - A polarized logit model.pdf:application/pdf;ScienceDirect Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/VAXT6JWX/S0965856413001122.html:text/html}
}

@book{hampel_robust_2011,
	title = {Robust {Statistics}: {The} {Approach} {Based} on {Influence} {Functions}},
	isbn = {978-1-118-15068-9},
	shorttitle = {Robust {Statistics}},
	abstract = {The Wiley-Interscience Paperback Series consists of selected books that have been made more accessible to consumers in an effort to increase global appeal and general circulation. With these new unabridged softcover volumes, Wiley hopes to extend the lives of these works by making them available to future generations of statisticians, mathematicians, and scientists. "This is a nice book containing a wealth of information, much of it due to the authors. . . . If an instructor designing such a course wanted a textbook, this book would be the best choice available. . . . There are many stimulating exercises, and the book also contains an excellent index and an extensive list of references." {\textemdash}Technometrics "[This] book should be read carefully by anyone who is interested in dealing with statistical models in a realistic fashion." {\textemdash}American Scientist Introducing concepts, theory, and applications, Robust Statistics is accessible to a broad audience, avoiding allusions to high-powered mathematics while emphasizing ideas, heuristics, and background. The text covers the approach based on the influence function (the effect of an outlier on an estimater, for example) and related notions such as the breakdown point. It also treats the change-of-variance function, fundamental concepts and results in the framework of estimation of a single parameter, and applications to estimation of covariance matrices and regression parameters.},
	language = {en},
	publisher = {John Wiley \& Sons},
	author = {Hampel, Frank R. and Ronchetti, Elvezio M. and Rousseeuw, Peter J. and Stahel, Werner A.},
	month = sep,
	year = {2011},
	keywords = {Mathematics / Probability \& Statistics / General, Mathematics / Probability \& Statistics / Stochastic Processes}
}

@incollection{bianco_robust_1996,
	series = {Lecture {Notes} in {Statistics}},
	title = {Robust {Estimation} in the {Logistic} {Regression} {Model}},
	copyright = {{\textcopyright}1996 Springer-Verlag New York, Inc.},
	isbn = {978-0-387-94660-3 978-1-4612-2380-1},
	url = {http://link.springer.com/chapter/10.1007/978-1-4612-2380-1_2},
	abstract = {A new class of robust and Fisher-consistent M-estimates for the logistic regression models is introduced. We show that these estimates are consistent and asymptotically normal. Their robustness is studied through the computation of asymptotic bias curves under point-mass contamination for the case when the covariates follow a multivariate normal distribution. We illustrate the behavior of these estimates with two data sets. Finally, we mention some possible extensions of these M-estimates for a multinomial response.},
	language = {en},
	number = {109},
	urldate = {2016-04-06},
	booktitle = {Robust {Statistics}, {Data} {Analysis}, and {Computer} {Intensive} {Methods}},
	publisher = {Springer New York},
	author = {Bianco, Ana M. and Yohai, V{\'i}ctor J.},
	editor = {Rieder, Helmut},
	year = {1996},
	note = {DOI: 10.1007/978-1-4612-2380-1\_2},
	keywords = {Computational Mathematics and Numerical Analysis, estimates, Logistic regression model, M-estimates, Primary 62F35, 62J12, Probability Theory and Stochastic Processes, robust, secondary 62F12, Statistics, general},
	pages = {17--34},
	file = {Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/II89U2HG/Bianco and Yohai - 1996 - Robust Estimation in the Logistic Regression Model.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/S9ZK3QG8/978-1-4612-2380-1_2.html:text/html}
}

@article{pregibon_resistant_1982,
	title = {Resistant {Fits} for {Some} {Commonly} {Used} {Logistic} {Models} with {Medical} {Applications}},
	volume = {38},
	issn = {0006-341X},
	url = {http://www.jstor.org/stable/2530463},
	doi = {10.2307/2530463},
	abstract = {Logistic regression-type models are used in many applications. Some examples include the classical dose-response experiment, prospective and retrospective studies of disease incidence (with and without matching), and the analysis of ordinal data. In most instances, the model is fitted by the method of maximum likelihood, which, like least squares, is sensitive to atypical observations. An alternative to maximum likelihood is proposed and illustrated by examples.},
	number = {2},
	urldate = {2016-04-06},
	journal = {Biometrics},
	author = {Pregibon, Daryl},
	year = {1982},
	pages = {485--498},
	file = {JSTOR Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/HTR26CV4/Pregibon - 1982 - Resistant Fits for Some Commonly Used Logistic Mod.pdf:application/pdf}
}

@article{carroll_robustness_1993,
	title = {On {Robustness} in the {Logistic} {Regression} {Model}},
	volume = {55},
	issn = {0035-9246},
	url = {http://www.jstor.org/stable/2345881},
	abstract = {We investigate robustness in the logistic regression model. Copas has studied two forms of robust estimator: a robust-resistant estimate of Pregibon and an estimate based on a misclassification model. He concluded that robust-resistant estimates are much more biased in small samples than the usual logistic estimate is and recommends a bias-corrected version of the misclassification estimate. We show that there are other versions of robust-resistant estimates which have bias often approximately the same as and sometimes even less than the logistic estimate; these estimates belong to the Mallows class. In addition, the corrected misclassification estimate is inconsistent at the logistic model; we develop a simple consistent modification. The modified estimate is a member of the Mallows class but, unlike most robust estimates, it has an interpretable tuning constant. The results are illustrated on data sets featuring different kinds of outliers.},
	number = {3},
	urldate = {2016-04-06},
	journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
	author = {Carroll, R. J. and Pederson, Shane},
	year = {1993},
	pages = {693--706},
	file = {2345881.pdf:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/ERFMPSPT/2345881.pdf:application/pdf}
}

@book{daganzo_multinomial_1979,
	title = {Multinomial {Probit}: {The} {Theory} and {Its} {Application} to {Demand} {Forecasting}},
	isbn = {978-0-12-201150-4},
	shorttitle = {Multinomial {Probit}},
	language = {en},
	publisher = {Academic Press},
	author = {Daganzo, Carlos},
	year = {1979},
	keywords = {Business \& Economics / Economics / Microeconomics, Business \& Economics / Forecasting}
}

@article{alptekinoglu_exponomial_2016,
	title = {The {Exponomial} {Choice} {Model}: {A} {New} {Alternative} for {Assortment} and {Price} {Optimization}},
	volume = {64},
	issn = {0030-364X},
	shorttitle = {The {Exponomial} {Choice} {Model}},
	url = {http://pubsonline.informs.org/doi/abs/10.1287/opre.2015.1459},
	doi = {10.1287/opre.2015.1459},
	abstract = {We investigate the use of a canonical version of a discrete choice model due to Daganzo (1979) [Daganzo C (1979) Multinomial Probit: The Theory and Its Application to Demand Forecasting (Academic Press, New York).] in optimal pricing and assortment planning. In contrast to multinomial and nested logit (the prevailing choice models used for optimizing prices and assortments), this model assumes a negatively skewed distribution of consumer utilities, an assumption we motivate by conceptual arguments as well as published work. The choice probabilities in this model can be derived in closed form as an exponomial (a linear function of exponential terms). The pricing and assortment planning insights we obtain from the exponomial choice (EC) model differ from the literature in two important ways. First, the EC model allows variable markups in optimal prices that increase with expected utilities. Second, when prices are exogenous, the optimal assortment may exhibit leapfrogging in prices, i.e., a product can be skipped in favor of a lower-priced one depending on the utility positions of neighboring products. These two plausible pricing and assortment patterns are ruled out by multinomial logit (and by nested logit within each nest). We provide structural results on optimal pricing for monopoly and oligopoly cases, and on the optimal assortments for both exogenous and endogenous prices. We also demonstrate how the EC model can be easily estimated{\textemdash}by establishing that the log-likelihood function is concave in model parameters and detailing an estimation example using real data.},
	number = {1},
	urldate = {2016-03-31},
	journal = {Operations Research},
	author = {Alptekino{\u g}lu, Ayd{\i}n and Semple, John H.},
	month = jan,
	year = {2016},
	pages = {79--93},
	file = {Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/VXBRBCM7/2016 - The Exponomial Choice Model A New Alternative for.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/W6V4IVW9/opre.2015.html:text/html}
}

@article{hennig_thoughts_2007,
	title = {Some thoughts about the design of loss functions},
	volume = {5},
	url = {https://ine.pt/revstat/pdf/rs070102.pdf},
	number = {1},
	urldate = {2016-04-06},
	journal = {REVSTAT{\textendash}Statistical Journal},
	author = {Hennig, Christian and Kutlukaya, Mahmut},
	year = {2007},
	pages = {19--39},
	file = {[PDF] from ine.pt:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/8W8RMBQT/Hennig and Kutlukaya - 2007 - Some thoughts about the design of loss functions.pdf:application/pdf}
}

@article{gneiting_strictly_2007,
	title = {Strictly {Proper} {Scoring} {Rules}, {Prediction}, and {Estimation}},
	volume = {102},
	issn = {0162-1459},
	url = {http://dx.doi.org/10.1198/016214506000001437},
	doi = {10.1198/016214506000001437},
	abstract = {Scoring rules assess the quality of probabilistic forecasts, by assigning a numerical score based on the predictive distribution and on the event or value that materializes. A scoring rule is proper if the forecaster maximizes the expected score for an observation drawn from the distribution F if he or she issues the probabilistic forecast F, rather than G /= F. It is strictly proper if the maximum is unique. In prediction problems, proper scoring rules encourage the forecaster to make careful assessments and to be honest. In estimation problems, strictly proper scoring rules provide attractive loss and utility functions that can be tailored to the problem at hand. This article reviews and develops the theory of proper scoring rules on general probability spaces, and proposes and discusses examples thereof. Proper scoring rules derive from convex functions and relate to information measures, entropy functions, and Bregman divergences. In the case of categorical variables, we prove a rigorous version of the Savage representation. Examples of scoring rules for probabilistic forecasts in the form of predictive densities include the logarithmic, spherical, pseudospherical, and quadratic scores. The continuous ranked probability score applies to probabilistic forecasts that take the form of predictive cumulative distribution functions. It generalizes the absolute error and forms a special case of a new and very general type of score, the energy score. Like many other scoring rules, the energy score admits a kernel representation in terms of negative definite functions, with links to inequalities of Hoeffding type, in both univariate and multivariate settings. Proper scoring rules for quantile and interval forecasts are also discussed. We relate proper scoring rules to Bayes factors and to cross-validation, and propose a novel form of cross-validation known as random-fold cross-validation. A case study on probabilistic weather forecasts in the North American Pacific Northwest illustrates the importance of propriety. We note optimum score approaches to point and quantile estimation, and propose the intuitively appealing interval score as a utility function in interval estimation that addresses width as well as coverage.},
	number = {477},
	urldate = {2014-09-05},
	journal = {Journal of the American Statistical Association},
	author = {Gneiting, Tilmann and Raftery, Adrian E},
	month = mar,
	year = {2007},
	pages = {359--378},
	file = {Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/WIE4I4XF/Gneiting and Raftery - 2007 - Strictly Proper Scoring Rules, Prediction, and Est.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/JVXCB9SA/016214506000001437.html:text/html}
}

@article{dawid_geometry_2006,
	title = {The geometry of proper scoring rules},
	volume = {59},
	issn = {0020-3157, 1572-9052},
	url = {http://link.springer.com/article/10.1007/s10463-006-0099-8},
	doi = {10.1007/s10463-006-0099-8},
	abstract = {A decision problem is defined in terms of an outcome space, an action space and a loss function. Starting from these simple ingredients, we can construct: Proper Scoring Rule; Entropy Function; Divergence Function; Riemannian Metric; and Unbiased Estimating Equation. From an abstract viewpoint, the loss function defines a duality between the outcome and action spaces, while the correspondence between a distribution and its Bayes act induces a self-duality. Together these determine a {\textquotedblleft}decision geometry{\textquotedblright} for the family of distributions on outcome space. This allows generalisation of many standard statistical concepts and properties. In particular we define and study generalised exponential families. Several examples are analysed, including a general Bregman geometry.},
	language = {en},
	number = {1},
	urldate = {2015-03-02},
	journal = {Annals of the Institute of Statistical Mathematics},
	author = {Dawid, A. P.},
	month = dec,
	year = {2006},
	keywords = {Bregman geometry, Decision geometry, Generalised exponential family, Information geometry, Proper scoring rule, Statistics for Business/Economics/Mathematical Finance/Insurance, Statistics, general, Unbiased estimating equation},
	pages = {77--93},
	file = {Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/GK34K7RR/Dawid - 2006 - The geometry of proper scoring rules.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/MZMH8JSP/s10463-006-0099-8.html:text/html}
}

@article{feroz_multimodal_2008,
	title = {Multimodal nested sampling: an efficient and robust alternative to {Markov} {Chain} {Monte} {Carlo} methods for astronomical data analyses},
	volume = {384},
	issn = {0035-8711, 1365-2966},
	shorttitle = {Multimodal nested sampling},
	url = {http://mnras.oxfordjournals.org/content/384/2/449},
	doi = {10.1111/j.1365-2966.2007.12353.x},
	abstract = {In performing a Bayesian analysis of astronomical data, two difficult problems often emerge. First, in estimating the parameters of some model for the data, the resulting posterior distribution may be multimodal or exhibit pronounced (curving) degeneracies, which can cause problems for traditional Markov Chain Monte Carlo (MCMC) sampling methods. Secondly, in selecting between a set of competing models, calculation of the Bayesian evidence for each model is computationally expensive using existing methods such as thermodynamic integration. The nested sampling method introduced by Skilling, has greatly reduced the computational expense of calculating evidence and also produces posterior inferences as a by-product. This method has been applied successfully in cosmological applications by Mukherjee, Parkinson \& Liddle, but their implementation was efficient only for unimodal distributions without pronounced degeneracies. Shaw, Bridges \& Hobson recently introduced a clustered nested sampling method which is significantly more efficient in sampling from multimodal posteriors and also determines the expectation and variance of the final evidence from a single run of the algorithm, hence providing a further increase in efficiency. In this paper, we build on the work of Shaw et al. and present three new methods for sampling and evidence evaluation from distributions that may contain multiple modes and significant degeneracies in very high dimensions; we also present an even more efficient technique for estimating the uncertainty on the evaluated evidence. These methods lead to a further substantial improvement in sampling efficiency and robustness, and are applied to two toy problems to demonstrate the accuracy and economy of the evidence calculation and parameter estimation. Finally, we discuss the use of these methods in performing Bayesian object detection in astronomical data sets, and show that they significantly outperform existing MCMC techniques. An implementation of our methods will be publicly released shortly.},
	language = {en},
	number = {2},
	urldate = {2016-04-11},
	journal = {Monthly Notices of the Royal Astronomical Society},
	author = {Feroz, F. and Hobson, M. P.},
	month = feb,
	year = {2008},
	keywords = {methods: data analysis, methods: statistical},
	pages = {449--463},
	file = {Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/ZPCRKNGT/Feroz and Hobson - 2008 - Multimodal nested sampling an efficient and robus.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/JHH4N5N6/449.html:text/html}
}

@article{feroz_multinest_2009,
	title = {{MultiNest}: an efficient and robust {Bayesian} inference tool for cosmology and particle physics},
	volume = {398},
	issn = {0035-8711, 1365-2966},
	shorttitle = {{MultiNest}},
	url = {http://mnras.oxfordjournals.org/content/398/4/1601},
	doi = {10.1111/j.1365-2966.2009.14548.x},
	abstract = {We present further development and the first public release of our multimodal nested sampling algorithm, called MultiNest. This Bayesian inference tool calculates the evidence, with an associated error estimate, and produces posterior samples from distributions that may contain multiple modes and pronounced (curving) degeneracies in high dimensions. The developments presented here lead to further substantial improvements in sampling efficiency and robustness, as compared to the original algorithm presented in Feroz \& Hobson, which itself significantly outperformed existing Markov chain Monte Carlo techniques in a wide range of astrophysical inference problems. The accuracy and economy of the MultiNest algorithm are demonstrated by application to two toy problems and to a cosmological inference problem focusing on the extension of the vanilla $\Lambda$ cold dark matter model to include spatial curvature and a varying equation of state for dark energy. The MultiNest software, which is fully parallelized using MPI and includes an interface to CosmoMC, is available at http://www.mrao.cam.ac.uk/software/multinest/. It will also be released as part of the SuperBayeS package, for the analysis of supersymmetric theories of particle physics, at http://www.superbayes.org.},
	language = {en},
	number = {4},
	urldate = {2016-04-11},
	journal = {Monthly Notices of the Royal Astronomical Society},
	author = {Feroz, F. and Hobson, M. P. and Bridges, M.},
	month = oct,
	year = {2009},
	keywords = {methods: data analysis, methods: statistical},
	pages = {1601--1614},
	file = {Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/KGCS7FPH/Feroz et al. - 2009 - MultiNest an efficient and robust Bayesian infere.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/C8XM6ANE/1601.html:text/html}
}

@article{skilling_nested_2006,
	title = {Nested sampling for general {Bayesian} computation},
	volume = {1},
	url = {http://projecteuclid.org/euclid.ba/1340370944},
	number = {4},
	urldate = {2016-04-11},
	journal = {Bayesian analysis},
	author = {Skilling, John},
	year = {2006},
	pages = {833--859},
	file = {euclid.ba.1340370944.pdf:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/9KV2A9PE/euclid.ba.1340370944.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/E6XF6KUE/1340370944.html:text/html}
}

@article{jenkinson_frequency_1955,
	title = {The frequency distribution of the annual maximum (or minimum) values of meteorological elements},
	volume = {81},
	copyright = {Copyright {\textcopyright} 1955 Royal Meteorological Society},
	issn = {1477-870X},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/qj.49708134804/abstract},
	doi = {10.1002/qj.49708134804},
	abstract = {It is shown that the probability P that the annual maximum value of a meteorological element is less than a given value x can be expressed as exp  where a and k are constants such that ak is positive. The parameters a and k can be evaluated from data of annual maximum values for a given period of years. Hence we derive the average highest and lowest in sets of T annual maxima, and also the maximum value to be expected once in T years.},
	language = {en},
	number = {348},
	urldate = {2016-04-11},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Jenkinson, A. F.},
	month = apr,
	year = {1955},
	pages = {158--171},
	file = {Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/U3GZJQ8D/Jenkinson - 1955 - The frequency distribution of the annual maximum (.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/5586BC8A/abstract\;jsessionid=C230EEDE346BC3DC571575BE9BF1DA33.html:text/html}
}

@article{revelt_mixed_1998,
	title = {Mixed logit with repeated choices: households' choices of appliance efficiency level},
	volume = {80},
	shorttitle = {Mixed logit with repeated choices},
	url = {http://www.mitpressjournals.org/doi/abs/10.1162/003465398557735},
	number = {4},
	urldate = {2016-04-11},
	journal = {Review of economics and statistics},
	author = {Revelt, David and Train, Kenneth},
	year = {1998},
	pages = {647--657},
	file = {[PDF] from mitpressjournals.org:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/JQU2P2E3/Revelt and Train - 1998 - Mixed logit with repeated choices households' cho.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/XNGWP3GG/003465398557735.html:text/html}
}

@article{recker_discrete_1995,
	title = {Discrete choice with an oddball alternative},
	volume = {29},
	issn = {0191-2615},
	url = {http://www.sciencedirect.com/science/article/pii/019126159500002U},
	doi = {10.1016/0191-2615(95)00002-U},
	abstract = {A discrete choice model is presented that explicitly recognizes differences in the error structure associated with a single {\textquotedblleft}oddball{\textquotedblright} alternative within the choice set that has properties not common to the other alternatives. The model purportedly resolves questions related to the use of alternative-specific variables in transportation choice models to capture the effects of attributes unique to a single travel alternative, such as {\textquotedblleft}schedule frequency{\textquotedblright} in the case of modal choice between personal auto and public transit. The model, which shares the general error structure of multinomial logit, is shown to be a modification of a multinomial logit subchoice by terms involving the exponential integral. The model is shown to yield different results from those produced by an equivalent multinomial logit specification. Comparisons to multinomial probit and nested logit formulations are also made.},
	number = {3},
	urldate = {2016-04-11},
	journal = {Transportation Research Part B: Methodological},
	author = {Recker, W. W.},
	month = jun,
	year = {1995},
	pages = {201--211},
	file = {ScienceDirect Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/ZZ4BJGPD/Recker - 1995 - Discrete choice with an oddball alternative.pdf:application/pdf;ScienceDirect Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/NM6G6QQI/019126159500002U.html:text/html}
}

@article{steckel_heterogeneous_1988,
	title = {A {Heterogeneous} {Conditional} {Logit} {Model} of {Choice}},
	volume = {6},
	issn = {0735-0015},
	url = {http://www.jstor.org/stable/1391892},
	doi = {10.2307/1391892},
	abstract = {Aggregate forecasts using McFadden's conditional logit model of discrete choice harbor the unrealistic implicit assumption of a random-utility distribution that is homogeneous across both alternatives and individuals. This article relaxes that assumption. A choice model is developed that describes the random-utility component as a probability-mixture model. Some numerical results illustrate that the derived model is not constrained by the independence-of-irrelevant-alternatives property. An experimental test of visual perceptions demonstrates the potential superiority of the model.},
	number = {3},
	urldate = {2016-04-11},
	journal = {Journal of Business \& Economic Statistics},
	author = {Steckel, Joel H. and Vanhonacker, Wilfried R.},
	year = {1988},
	pages = {391--398}
}


@article{berkson_minimum_1980,
	title = {Minimum {Chi}-{Square}, not {Maximum} {Likelihood}!},
	volume = {8},
	issn = {0090-5364},
	url = {http://www.jstor.org/stable/2240587},
	abstract = {The sovereignty of MLE is questioned. Minimum $\chi$2 $\lambda$ yields the same estimating equations as MLE. For many cases, as illustrated in presented examples, and further algorithmic exploration in progress may show that for all cases, minimum $\chi$2 $\lambda$ estimates are available. In this sense minimum $\chi$2 is the basic principle of estimation. The criterion of asymptotic sufficiency which has been called "second order efficiency" is rejected as a criterion of goodness of estimate as against some loss function such as the mean squared error. The relation between MLE and sufficiency is not assured, as illustrated in an example in which MLE yields $\infty$ as estimate with samples that have different values of the sufficient statistic. Other examples are cited in which minimal sufficient statistics exist but where the MLE is not sufficient. The view is advanced that statistics is a science, not mathematics or philosophy (inference) and as such requires that any claimed attributes of the MLE must be testable by a Monte Carlo experiment.},
	number = {3},
	urldate = {2016-04-11},
	journal = {The Annals of Statistics},
	author = {Berkson, Joseph},
	year = {1980},
	pages = {457--487},
	file = {2240587.pdf:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/HBG2GNMZ/2240587.pdf:application/pdf}
}

@article{bhat_heteroscedastic_1995,
	title = {A heteroscedastic extreme value model of intercity travel mode choice},
	volume = {29},
	issn = {0191-2615},
	url = {http://www.sciencedirect.com/science/article/pii/0191261595000156},
	doi = {10.1016/0191-2615(95)00015-6},
	abstract = {Estimation of disaggregate mode choice models to estimate the ridership share on a proposed new (or improved) intercity travel service and to identify the modes from which existing intercity travelers will be diverted to the new or upgraded service constitutes a critical part of evaluating alternative travel service proposals to alleviate intercity travel congestion. This paper develops a new heteroscedastic extreme value model of intercity mode choice that overcomes the {\textquoteleft}independence of irrelevant alternatives{\textquoteright} (IIA) property of the commonly used multinomial logit model. The proposed model allows a more flexible cross-elasticity structure among alternatives than the nested logit model. It is also simple, intuitive and much less of a computational burden than the multinomial probit model. The paper discusses the non-IIA property of the heteroscedastic extreme value model and presents an efficient and accurate Gaussian quadrature technique to estimate the heteroscedastic model using the maximum likelihood method. The multinomial logit, alternative nested logit structures, and the heteroscedastic model are estimated to examine the impact of improved rail service on business travel in the Toronto-Montreal corridor. The nested logit structures are either inconsistent with utility maximization principles or are not significantly better than the multinomial logit model. The heteroscedastic extreme value model, however, is found to be superior to the multinomial logit model. The heteroscedastic model predicts smaller increases in rail shares and smaller decreases in non-rail shares than the multinomial logit in response to rail-service improvements. It also suggests a larger percentage decrease in air share and a smaller percentage decrease in auto share than the multinomial logit. Thus, the multinomial logit model is likely to provide overly optimistic projections of rail ridership and revenue, and of alleviation in inter-city travel congestion in general, and highway traffic congestion in particular. These findings point to the limitations of the multinomial logit and nested logit models in studying intercity mode choice behavior and to the usefulness of the heteroscedastic model proposed in this paper.},
	number = {6},
	urldate = {2015-06-03},
	journal = {Transportation Research Part B: Methodological},
	author = {Bhat, Chandra R.},
	month = dec,
	year = {1995},
	pages = {471--483},
	file = {ScienceDirect Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/QI7C2IIC/Bhat - 1995 - A heteroscedastic extreme value model of intercity.pdf:application/pdf;ScienceDirect Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/AIEIWUQ8/0191261595000156.html:text/html}
}

@article{donoso_maximum_2011,
	title = {A {Maximum} {Entropy} {Estimator} for the {Aggregate} {Hierarchical} {Logit} {Model}},
	volume = {13},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {http://www.mdpi.com/1099-4300/13/8/1425},
	doi = {10.3390/e13081425},
	abstract = {A new approach for estimating the aggregate hierarchical logit model is presented. Though usually derived from random utility theory assuming correlated stochastic errors, the model can also be derived as a solution to a maximum entropy problem. Under the latter approach, the Lagrange multipliers of the optimization problem can be understood as parameter estimators of the model. Based on theoretical analysis and Monte Carlo simulations of a transportation demand model, it is demonstrated that the maximum entropy estimators have statistical properties that are superior to classical maximum likelihood estimators, particularly for small or medium-size samples. The simulations also generated reduced bias in the estimates of the subjective value of time and consumer surplus.},
	language = {en},
	number = {8},
	urldate = {2014-09-21},
	journal = {Entropy},
	author = {Donoso, Pedro and De Grange, Louis and Gonz{\'a}lez, Felipe},
	month = aug,
	year = {2011},
	keywords = {hierarchical logit model, lagrange multipliers, maximum entropy, maximum likelihood},
	pages = {1425--1445},
	file = {Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/HBZ4TZ47/Donoso et al. - 2011 - A Maximum Entropy Estimator for the Aggregate Hier.pdf:application/pdf;Snapshot:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/RKRUGT8H/1425.html:text/html}
}

@article{mcfadden_econometric_1980,
	title = {Econometric {Models} for {Probabilistic} {Choice} {Among} {Products}},
	volume = {53},
	issn = {0021-9398},
	url = {http://www.jstor.org/stable/2352205},
	abstract = {This paper reviews several recent developments in econometric demand analysis which may be of interest in market research. Econometric models of probabilistic choice, suitable for forecasting choice among existing or new brands, or switching between brands, are surveyed. These models incorporate attribute descriptions of commodities, making them statistical counterparts of the Court-Griliches-Lancaster theory of consumer behavior. Particular attention is given to models which yield tree structures of similarities between alternatives. Also reviewed are methods for estimating econometric models of probabilistic choice from "point-of-sale" sample surveys.},
	number = {3},
	urldate = {2016-04-11},
	journal = {The Journal of Business},
	author = {McFadden, Daniel},
	year = {1980},
	pages = {S13--S29},
	file = {JSTOR Full Text PDF:/home/timothy/.zotero/zotero/u5115c05.default/zotero/storage/M7TPKR7Z/McFadden - 1980 - Econometric Models for Probabilistic Choice Among .pdf:application/pdf}
}

@article{brog_individualized1998,
  title={Individualized marketing: implications for transportation demand management},
  author={Br{\"o}g, Werner},
  journal={Transportation Research Record: Journal of the Transportation Research Board},
  number={1618},
  pages={116--121},
  year={1998},
  publisher={Transportation Research Board of the National Academies}
}

@article{gensch_targeting_1984,
  title={Targeting the switchable industrial customer},
  author={Gensch, Dennis H},
  journal={Marketing Science},
  volume={3},
  number={1},
  pages={41--54},
  year={1984},
  publisher={INFORMS}
}

@article{jones_scipy_2014,
  title={$\{$SciPy$\}$: open source scientific tools for $\{$Python$\}$},
  author={Jones, Eric and Oliphant, Travis and Peterson, Pearu},
  year={2014}
}

@article{van_numpy_2011,
  title={The NumPy array: a structure for efficient numerical computation},
  author={Van Der Walt, Stefan and Colbert, S Chris and Varoquaux, Gael},
  journal={Computing in Science \& Engineering},
  volume={13},
  number={2},
  pages={22--30},
  year={2011},
  publisher={AIP Publishing}
}

@inproceedings{mckinney_data_2010,
  title={Data structures for statistical computing in Python},
  author={McKinney, Wes and others},
  booktitle={Proceedings of the 9th Python in Science Conference},
  volume={445},
  pages={51--56},
  year={2010}
}

@article{chorus_random_2014,
  title={Random regret minimization for consumer choice modeling: Assessment of empirical evidence},
  author={Chorus, Caspar and van Cranenburgh, Sander and Dekker, Thijs},
  journal={Journal of Business Research},
  volume={67},
  number={11},
  pages={2428--2436},
  year={2014},
  publisher={Elsevier}
}

@article{leong_contrasts_2015,
  title={Contrasts of relative advantage maximisation with random utility maximisation and regret minimisation},
  author={Leong, Waiyan and Hensher, David A},
  journal={Journal of Transport Economics and Policy (JTEP)},
  volume={49},
  number={1},
  pages={167--186},
  year={2015},
  publisher={Journal of Transport Economics and Policy}
}

@article{fisher_mathematical_1922,
  title={On the mathematical foundations of theoretical statistics},
  author={Fisher, Ronald Aylmer},
  journal={Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character},
  volume={222},
  pages={309--368},
  year={1922},
  publisher={JSTOR}
}

@book{keener_statistical_2010,
  title={{Theoretical Statistics: Topics for a Core Course}},
  author={Keener, Robert W},
  year={2010},
  publisher={Springer},
  isbn={978-0-387-93838-7}
}

@article{czado_orthogonalizing_1992,
  title={Orthogonalizing parametric link transformation families in binary regression analysis},
  author={Czado, Claudia and Santner, Thomas J},
  journal={Canadian Journal of Statistics},
  volume={20},
  number={1},
  pages={51--61},
  year={1992},
  publisher={Wiley Online Library}
}

@article{taylor_cost_1988,
  title={The cost of generalizing logistic regression},
  author={Taylor, Jeremy MG},
  journal={Journal of the American Statistical Association},
  volume={83},
  number={404},
  pages={1078--1083},
  year={1988},
  publisher={Taylor \& Francis}
}

@techreport{sfcta_san_2010,
	title = {San {Francisco} {Mobility}, {Access}, and {Pricing} {Study}},
	url = {http://www.sfcta.org/sites/default/files/content/Planning/CongestionPricingFeasibilityStudy/PDFs/MAPS_study_final_lo_res.pdf},
	institution = {San Francisco County Transportation Authority},
	author = {{San Francisco County Transportation Authority}},
	month = dec,
	year = {2010},
	pages = {63}
}

@article{chorus_paving_2016,
  title={Paving the way towards superstar destinations: Models of convex demand for quality},
  author={Chorus, Caspar G},
  journal={Environment and Planning B: Planning and Design},
  volume={0},
  number={0},
  pages={1--19},
  year={2016},
  publisher={Sage}
}

@article{briesch_semiparametric_2002,
  title={Semiparametric Estimation of Brand Choice Behavior},
  author={Briesch, Richard A and Chintagunta, Pradeep K and Matzkin, Rosa L},
  journal={Journal of the American Statistical Association},
  volume={97},
  number={460},
  pages={973--982},
  year={2002},
  publisher={Taylor \& Francis},
  doi = {10.1198/016214502388618762}
}

@article{morgan_extended_1988,
  title={Extended Models for Quantal Response data},
  author={Morgan, B. J. T.},
  journal={Statistica Neerlandica},
  volume={42},
  number={4},
  pages={253--272},
  year={1988},
  publisher={Blackwell}
}

@article{presnell_ios_2004,
  title={The IOS Test for Model Misspecification},
  author={Presnell, Brett and Boos, Dennis},
  journal={Journal of the American Statistical Association},
  volume={99},
  number={465},
  pages={216--227},
  year={2004},
  publisher={Taylor \& Francis}
}

@article{spiegelhalter_bayesian_2002,
  title={Bayesian measures of model complexity and fit},
  author={Spiegelhalter, David J and Best, Nicola G and Carlin, Bradley P and van der Linde, Angelika},
  journal={Journal of the Royal Statistical Society B},
  volume={64},
  number={4},
  pages={583--639},
  year={2002},
  publisher={Wiley}
}

@article{diciccio_bootstrap_1996,
  title={Bootstrap Confidence Intervals},
  author={DiCiccio, Thomas J and Efron, Bradley},
  journal={Statistical Science},
  volume={11},
  number={3},
  pages={189--228},
  year={1996}
}

@book{efron_introduction_1993,
	title = {An Introduction to the Bootstrap},
	isbn = {978-0-412-04231-7},
	publisher = {Springer},
	author = {Efron, Bradley and Tibshirani, Robert},
	year = {1993},
}

@article{jennings_judging_1986,
  title={Judging Inference Adequacy in Logistic Regression},
  author={Jennings, Dennis E},
  journal={Journal of the American Statistical Association},
  volume={81},
  number={394},
  pages={471--476},
  year={1986}
}

@article{pawitan_2000_reminder,
  title={{A Reminder of the Fallibility of the Wald Statistic: Likelihood Explanation}},
  author={Pawitan, Yudi},
  journal={The American Statistician},
  volume={54},
  number={1},
  pages={54--56},
  year={2000}
}